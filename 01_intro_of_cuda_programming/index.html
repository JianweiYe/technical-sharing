<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>CUDA Programming: Technical Overview</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="
href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/lucide@latest"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        primary: '#76b900', // NVIDIA green
                        dark: '#111111',
                        light: '#f9f9f9',
                    },
                    fontFamily: {
                        'sans': ['Inter', 'sans-serif'],
                        'geist-mono': ['SF Mono', 'Menlo', 'Monaco', 'Courier', 'monospace'],
                    },
                }
            }
        }
    </script>
</head>
<body class="bg-light text-dark antialiased">
    <header class="sticky top-0 z-50 bg-white/90 backdrop-blur-sm border-b border-gray-200">
        <div class="container mx-auto px-4 py-4 flex justify-between items-center">
            <div class="flex items-center">
                <svg id="logo" class="w-8 h-8 mr-3" viewBox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                    <path d="M50 5 L95 95 L5 95 Z" fill="#76b900"/>
                </svg>
                <h1 class="text-xl font-semibold">CUDA Programming</h1>
            </div>
            <nav>
                <ul class="flex space-x-6">
                    <li><a href="#overview" class="hover:text-primary transition-colors">Overview</a></li>
                    <li><a href="#architecture" class="hover:text-primary transition-colors">Architecture</a></li>
                    <li><a href="#programming-model" class="hover:text-primary transition-colors">Programming Model</a></li>
                    <li><a href="#optimization" class="hover:text-primary transition-colors">Optimization</a></li>
                    <li><a href="#ai-applications" class="hover:text-primary transition-colors">AI Applications</a></li>
                    <li><a href="#resources" class="hover:text-primary transition-colors">Resources</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main class="container mx-auto px-4 py-8">
        <section id="intro" class="mb-20">
            <div class="bg-dark text-white rounded-xl p-10 mb-10">
                <h2 class="text-4xl font-bold mb-6">CUDA Programming: Technical Overview</h2>
                <p class="text-xl mb-8">A comprehensive technical presentation on NVIDIA's CUDA platform for parallel computing and GPU acceleration.</p>
                <div class="flex items-center">
                    <div class="mr-4 p-2 bg-primary rounded-full">
                        <i data-lucide="zap" class="w-6 h-6 text-dark"></i>
                    </div>
                    <p class="font-geist-mono">Prepared for technical team training</p>
                </div>
            </div>
        </section>

        <section id="overview" class="mb-20">
            <div class="border-l-4 border-primary pl-4 mb-6">
                <h2 class="text-3xl font-bold">1. Introduction & Overview</h2>
            </div>

            <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 mb-10">
                <div>
                    <h3 class="text-xl font-semibold mb-4">What is CUDA?</h3>
                    <p class="mb-4">CUDA (Compute Unified Device Architecture) is a parallel computing platform and programming model developed by NVIDIA that enables dramatic increases in computing performance by leveraging the power of the GPU.</p>
                    <p class="mb-4">CUDA allows software developers to use NVIDIA GPUs for general-purpose processing, an approach known as GPGPU (General-Purpose computing on Graphics Processing Units).</p>
                    <div class="p-4 bg-gray-100 rounded-lg mb-4">
                        <p class="font-geist-mono text-sm">"CUDA serves as a software layer offering direct access to the GPU's virtual instruction set for executing compute kernels."</p>
                    </div>
                </div>
                
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                    <h3 class="text-xl font-semibold mb-4">Key CUDA Features</h3>
                    <ul class="space-y-3">
                        <li class="flex items-start">
                            <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                <i data-lucide="check" class="w-4 h-4 text-primary"></i>
                            </div>
                            <span>Parallel computing platform and API</span>
                        </li>
                        <li class="flex items-start">
                            <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                <i data-lucide="check" class="w-4 h-4 text-primary"></i>
                            </div>
                            <span>Direct access to GPU virtual instruction set and memory</span>
                        </li>
                        <li class="flex items-start">
                            <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                <i data-lucide="check" class="w-4 h-4 text-primary"></i>
                            </div>
                            <span>Support for C, C++, Fortran, Python and other languages</span>
                        </li>
                        <li class="flex items-start">
                            <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                <i data-lucide="check" class="w-4 h-4 text-primary"></i>
                            </div>
                            <span>Libraries, compiler directives, extensions for languages</span>
                        </li>
                        <li class="flex items-start">
                            <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                <i data-lucide="check" class="w-4 h-4 text-primary"></i>
                            </div>
                            <span>Massively parallel processing architecture</span>
                        </li>
                    </ul>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">CUDA Timeline</h3>
                <div class="relative">
                    <div class="absolute left-0 top-0 h-full w-1 bg-primary/20 ml-2"></div>
                    <div class="space-y-6 relative">
                        <div class="flex">
                            <div class="z-10 flex-shrink-0 w-5 h-5 rounded-full bg-primary"></div>
                            <div class="ml-4">
                                <h4 class="font-semibold">2004</h4>
                                <p>Ian Buck joins NVIDIA to oversee CUDA development</p>
                            </div>
                        </div>
                        <div class="flex">
                            <div class="z-10 flex-shrink-0 w-5 h-5 rounded-full bg-primary"></div>
                            <div class="ml-4">
                                <h4 class="font-semibold">2006</h4>
                                <p>CUDA officially created by NVIDIA</p>
                            </div>
                        </div>
                        <div class="flex">
                            <div class="z-10 flex-shrink-0 w-5 h-5 rounded-full bg-primary"></div>
                            <div class="ml-4">
                                <h4 class="font-semibold">February 2007</h4>
                                <p>Initial CUDA SDK released for Windows and Linux</p>
                            </div>
                        </div>
                        <div class="flex">
                            <div class="z-10 flex-shrink-0 w-5 h-5 rounded-full bg-primary"></div>
                            <div class="ml-4">
                                <h4 class="font-semibold">2008</h4>
                                <p>Mac OS X support added in version 2.0</p>
                            </div>
                        </div>
                        <div class="flex">
                            <div class="z-10 flex-shrink-0 w-5 h-5 rounded-full bg-primary"></div>
                            <div class="ml-4">
                                <h4 class="font-semibold">Around 2015</h4>
                                <p>CUDA focus shifts toward neural networks and AI</p>
                            </div>
                        </div>
                        <div class="flex">
                            <div class="z-10 flex-shrink-0 w-5 h-5 rounded-full bg-primary"></div>
                            <div class="ml-4">
                                <h4 class="font-semibold">2023-Present</h4>
                                <p>CUDA DTX (Distributed Execution) development for data center scale</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div>
                <h3 class="text-xl font-semibold mb-4">Why CUDA Matters</h3>
                <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
                    <div class="bg-white p-6 rounded-xl border border-gray-200 shadow-sm">
                        <div class="p-2 bg-primary/10 rounded-full w-fit mb-4">
                            <i data-lucide="zap" class="w-5 h-5 text-primary"></i>
                        </div>
                        <h4 class="font-semibold mb-2">Parallel Processing</h4>
                        <p class="text-sm text-gray-700">CUDA breaks down tasks into thousands of threads that run simultaneously, enabling massive parallel processing capacity.</p>
                    </div>
                    <div class="bg-white p-6 rounded-xl border border-gray-200 shadow-sm">
                        <div class="p-2 bg-primary/10 rounded-full w-fit mb-4">
                            <i data-lucide="bar-chart" class="w-5 h-5 text-primary"></i>
                        </div>
                        <h4 class="font-semibold mb-2">Performance Boost</h4>
                        <p class="text-sm text-gray-700">Exceptional speed for computationally intensive tasks that can be parallelized, often 10-100x faster than CPU-only processing.</p>
                    </div>
                    <div class="bg-white p-6 rounded-xl border border-gray-200 shadow-sm">
                        <div class="p-2 bg-primary/10 rounded-full w-fit mb-4">
                            <i data-lucide="brain-circuit" class="w-5 h-5 text-primary"></i>
                        </div>
                        <h4 class="font-semibold mb-2">AI Development</h4>
                        <p class="text-sm text-gray-700">Industry standard for AI, with optimized math libraries that have been developed over a decade for NVIDIA hardware.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="architecture" class="mb-20">
            <div class="border-l-4 border-primary pl-4 mb-6">
                <h2 class="text-3xl font-bold">2. CUDA Architecture</h2>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">CPU vs. GPU Architecture</h3>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8 mb-6">
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold text-center mb-4">CPU</h4>
                        <div class="h-48 mb-4 bg-gray-100 rounded-lg flex justify-center items-center p-4">
                            <div class="text-center">
                                <div class="flex justify-center mb-4">
                                    <div class="w-16 h-16 bg-blue-500 rounded-md flex items-center justify-center text-white font-semibold mx-2">Core</div>
                                    <div class="w-16 h-16 bg-blue-500 rounded-md flex items-center justify-center text-white font-semibold mx-2">Core</div>
                                </div>
                                <div class="flex justify-center">
                                    <div class="w-16 h-16 bg-blue-500 rounded-md flex items-center justify-center text-white font-semibold mx-2">Core</div>
                                    <div class="w-16 h-16 bg-blue-500 rounded-md flex items-center justify-center text-white font-semibold mx-2">Core</div>
                                </div>
                                <p class="text-xs text-gray-600 mt-2">Visualization of a typical multi-core CPU</p>
                            </div>
                        </div>
                        <ul class="space-y-2">
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="cpu" class="w-3 h-3 text-blue-500"></i>
                                </div>
                                <span class="text-sm">Few powerful cores (4-128)</span>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="cpu" class="w-3 h-3 text-blue-500"></i>
                                </div>
                                <span class="text-sm">Optimized for serial processing</span>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="cpu" class="w-3 h-3 text-blue-500"></i>
                                </div>
                                <span class="text-sm">Large cache memory</span>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="cpu" class="w-3 h-3 text-blue-500"></i>
                                </div>
                                <span class="text-sm">Advanced flow control</span>
                            </li>
                        </ul>
                    </div>
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold text-center mb-4">GPU</h4>
                        <div class="h-48 mb-4 bg-gray-100 rounded-lg flex justify-center items-center p-4">
                            <div class="text-center">
                                <div class="grid grid-cols-8 gap-1 mb-1">
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                </div>
                                <div class="grid grid-cols-8 gap-1">
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                </div>
                                <div class="text-center text-gray-400 my-2">...</div>
                                <div class="grid grid-cols-8 gap-1">
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                    <div class="w-6 h-4 bg-primary rounded-sm"></div>
                                </div>
                                <p class="text-xs text-gray-600 mt-2">Visualization of thousands of CUDA cores</p>
                            </div>
                        </div>
                        <ul class="space-y-2">
                            <li class="flex items-start">
                                <div class="p-1 bg-primary/10 rounded-full mr-2 mt-1">
                                    <i data-lucide="cpu" class="w-3 h-3 text-primary"></i>
                                </div>
                                <span class="text-sm">Thousands of cores (thousands to tens of thousands)</span>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-primary/10 rounded-full mr-2 mt-1">
                                    <i data-lucide="cpu" class="w-3 h-3 text-primary"></i>
                                </div>
                                <span class="text-sm">Designed for parallel processing</span>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-primary/10 rounded-full mr-2 mt-1">
                                    <i data-lucide="cpu" class="w-3 h-3 text-primary"></i>
                                </div>
                                <span class="text-sm">Smaller cache, higher bandwidth memory</span>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-primary/10 rounded-full mr-2 mt-1">
                                    <i data-lucide="cpu" class="w-3 h-3 text-primary"></i>
                                </div>
                                <span class="text-sm">Simpler control logic, more ALUs</span>
                            </li>
                        </ul>
                    </div>
                </div>
                <p class="text-sm text-gray-600 mb-4">Key difference: CPUs are optimized for low latency while GPUs are optimized for high throughput.</p>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Streaming Multiprocessors (SMs)</h3>
                <div class="grid grid-cols-1 md:grid-cols-3 gap-8 mb-6">
                    <div class="col-span-1">
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm h-full">
                            <h4 class="font-semibold mb-3">What is an SM?</h4>
                            <p class="text-sm mb-4">Streaming Multiprocessors (SMs) are the fundamental computation units within NVIDIA GPUs. Each GPU consists of multiple SMs that execute instructions in parallel.</p>
                            <p class="text-sm">An SM contains execution cores (CUDA cores), registers, caches, schedulers, shared memory, and other resources needed to execute threads.</p>
                        </div>
                    </div>
                    <div class="col-span-2">
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm h-full">
                            <h4 class="font-semibold mb-3">SM Structure</h4>
                            <div class="flex flex-wrap">
                                <div class="w-full md:w-1/2 p-2">
                                    <div class="border border-gray-200 rounded-lg p-3">
                                        <h5 class="font-medium text-sm mb-2">Components</h5>
                                        <ul class="text-sm space-y-2">
                                            <li class="flex items-start">
                                                <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                                    <i data-lucide="cpu" class="w-3 h-3 text-primary"></i>
                                                </div>
                                                <span>CUDA Cores (Stream Processors)</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                                    <i data-lucide="code" class="w-3 h-3 text-primary"></i>
                                                </div>
                                                <span>Warp Schedulers</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                                    <i data-lucide="database" class="w-3 h-3 text-primary"></i>
                                                </div>
                                                <span>Shared Memory</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                                    <i data-lucide="layers" class="w-3 h-3 text-primary"></i>
                                                </div>
                                                <span>Register File</span>
                                            </li>
                                        </ul>
                                    </div>
                                </div>
                                <div class="w-full md:w-1/2 p-2">
                                    <div class="border border-gray-200 rounded-lg p-3">
                                        <h5 class="font-medium text-sm mb-2">Key Concepts</h5>
                                        <ul class="text-sm space-y-2">
                                            <li class="flex items-start">
                                                <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                                    <i data-lucide="boxes" class="w-3 h-3 text-primary"></i>
                                                </div>
                                                <span>Warps: Groups of 32 threads that execute in lockstep</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                                    <i data-lucide="activity" class="w-3 h-3 text-primary"></i>
                                                </div>
                                                <span>Occupancy: Ratio of active warps to maximum possible warps</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                                    <i data-lucide="split" class="w-3 h-3 text-primary"></i>
                                                </div>
                                                <span>Thread Blocks: Mapped to SMs for execution</span>
                                            </li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">CUDA Cores</h3>
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mb-6">
                    <div class="grid grid-cols-1 lg:grid-cols-3 gap-6">
                        <div class="lg:col-span-1">
                            <h4 class="font-semibold mb-3">Definition</h4>
                            <p class="text-sm mb-4">CUDA cores are processing units within NVIDIA GPUs that handle computing tasks in parallel. They are the fundamental execution units that perform floating-point and integer arithmetic operations.</p>
                            <div class="flex flex-col space-y-2">
                                <div class="flex items-center p-2 bg-primary/5 rounded-md">
                                    <i data-lucide="calculator" class="w-5 h-5 text-primary mr-3"></i>
                                    <span class="text-sm">Optimized for floating-point operations</span>
                                </div>
                                <div class="flex items-center p-2 bg-primary/5 rounded-md">
                                    <i data-lucide="network" class="w-5 h-5 text-primary mr-3"></i>
                                    <span class="text-sm">Execute thousands of operations simultaneously</span>
                                </div>
                                <div class="flex items-center p-2 bg-primary/5 rounded-md">
                                    <i data-lucide="braces" class="w-5 h-5 text-primary mr-3"></i>
                                    <span class="text-sm">Parallel task handling with threads</span>
                                </div>
                            </div>
                        </div>
                        <div class="lg:col-span-2">
                            <h4 class="font-semibold mb-3">CUDA Cores vs. Other Cores</h4>
                            <div class="overflow-x-auto">
                                <table class="min-w-full text-sm">
                                    <thead>
                                        <tr>
                                            <th class="text-left py-2 px-3 bg-gray-50 font-medium text-gray-700 rounded-tl-lg">Core Type</th>
                                            <th class="text-left py-2 px-3 bg-gray-50 font-medium text-gray-700">Primary Purpose</th>
                                            <th class="text-left py-2 px-3 bg-gray-50 font-medium text-gray-700">Characteristics</th>
                                            <th class="text-left py-2 px-3 bg-gray-50 font-medium text-gray-700 rounded-tr-lg">Optimization</th>
                                        </tr>
                                    </thead>
                                    <tbody class="divide-y divide-gray-200">
                                        <tr>
                                            <td class="py-2 px-3 font-medium">CUDA Cores</td>
                                            <td class="py-2 px-3">General-purpose parallel computing</td>
                                            <td class="py-2 px-3">Thousands of cores, optimized for parallel tasks</td>
                                            <td class="py-2 px-3">FP32, FP64 operations</td>
                                        </tr>
                                        <tr>
                                            <td class="py-2 px-3 font-medium">Tensor Cores</td>
                                            <td class="py-2 px-3">Matrix operations for AI/ML</td>
                                            <td class="py-2 px-3">Accelerates matrix multiplications</td>
                                            <td class="py-2 px-3">Mixed precision FP16, INT8, FP8</td>
                                        </tr>
                                        <tr>
                                            <td class="py-2 px-3 font-medium">CPU Cores</td>
                                            <td class="py-2 px-3">Sequential processing</td>
                                            <td class="py-2 px-3">Few powerful cores with complex logic</td>
                                            <td class="py-2 px-3">Complex branch prediction, large caches</td>
                                        </tr>
                                        <tr>
                                            <td class="py-2 px-3 font-medium">AMD Stream Processors</td>
                                            <td class="py-2 px-3">Parallel computing (AMD GPUs)</td>
                                            <td class="py-2 px-3">Similar to CUDA cores but for AMD architecture</td>
                                            <td class="py-2 px-3">Different efficiency profile</td>
                                        </tr>
                                    </tbody>
                                </table>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="flex flex-col md:flex-row gap-6">
                    <div class="w-full md:w-1/3 bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-3 flex items-center">
                            <div class="p-1 bg-primary/10 rounded-full mr-2">
                                <i data-lucide="zap" class="w-4 h-4 text-primary"></i>
                            </div>
                            Entry-Level
                        </h4>
                        <div class="border-t border-gray-200 pt-3">
                            <div class="flex justify-between mb-2">
                                <span class="text-sm text-gray-600">Typical CUDA Cores:</span>
                                <span class="font-medium">~896</span>
                            </div>
                            <div class="flex justify-between mb-2">
                                <span class="text-sm text-gray-600">Use Cases:</span>
                                <span class="font-medium">Basic Computing</span>
                            </div>
                            <div class="flex justify-between">
                                <span class="text-sm text-gray-600">Example GPU:</span>
                                <span class="font-medium">GTX 1650</span>
                            </div>
                        </div>
                    </div>
                    <div class="w-full md:w-1/3 bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-3 flex items-center">
                            <div class="p-1 bg-primary/10 rounded-full mr-2">
                                <i data-lucide="zap" class="w-4 h-4 text-primary"></i>
                            </div>
                            Mid-Range
                        </h4>
                        <div class="border-t border-gray-200 pt-3">
                            <div class="flex justify-between mb-2">
                                <span class="text-sm text-gray-600">Typical CUDA Cores:</span>
                                <span class="font-medium">3,584-4,864</span>
                            </div>
                            <div class="flex justify-between mb-2">
                                <span class="text-sm text-gray-600">Use Cases:</span>
                                <span class="font-medium">Gaming, Content Creation</span>
                            </div>
                            <div class="flex justify-between">
                                <span class="text-sm text-gray-600">Example GPU:</span>
                                <span class="font-medium">RTX 3070</span>
                            </div>
                        </div>
                    </div>
                    <div class="w-full md:w-1/3 bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-3 flex items-center">
                            <div class="p-1 bg-primary/10 rounded-full mr-2">
                                <i data-lucide="zap" class="w-4 h-4 text-primary"></i>
                            </div>
                            High-End
                        </h4>
                        <div class="border-t border-gray-200 pt-3">
                            <div class="flex justify-between mb-2">
                                <span class="text-sm text-gray-600">Typical CUDA Cores:</span>
                                <span class="font-medium">8,704-16,384+</span>
                            </div>
                            <div class="flex justify-between mb-2">
                                <span class="text-sm text-gray-600">Use Cases:</span>
                                <span class="font-medium">AI/ML, Scientific Computing</span>
                            </div>
                            <div class="flex justify-between">
                                <span class="text-sm text-gray-600">Example GPU:</span>
                                <span class="font-medium">RTX 4090, A100</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Memory Hierarchy</h3>
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mb-6">
                    <div class="w-full h-64 mb-6 bg-gray-50 rounded-lg flex items-center justify-center">
                        <div class="relative w-11/12 max-w-2xl">
                            <div class="absolute top-0 left-0 right-0 h-8 bg-red-500 rounded-t-md flex items-center justify-center text-white text-xs font-medium">
                                Registers (Fastest, Per Thread)
                            </div>
                            <div class="absolute top-8 left-4 right-4 h-10 bg-orange-500 flex items-center justify-center text-white text-xs font-medium">
                                L1 Cache / Shared Memory (Fast, Per SM)
                            </div>
                            <div class="absolute top-20 left-8 right-8 h-12 bg-yellow-500 flex items-center justify-center text-white text-xs font-medium">
                                L2 Cache (Medium, Shared by All SMs)
                            </div>
                            <div class="absolute top-36 left-12 right-12 h-16 bg-green-600 flex items-center justify-center text-white text-xs font-medium">
                                Global Memory (Slow, Accessible by All Threads)
                            </div>
                            <div class="absolute top-56 left-20 right-20 h-8 bg-blue-600 rounded-b-md flex items-center justify-center text-white text-xs font-medium">
                                Host Memory (CPU RAM, Slowest for GPU Access)
                            </div>
                        </div>
                    </div>
                    <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                        <div>
                            <h4 class="font-semibold mb-3">Memory Types</h4>
                            <ul class="space-y-2">
                                <li class="flex items-start">
                                    <div class="p-1 bg-red-100 rounded-full mr-2 mt-1">
                                        <i data-lucide="flame" class="w-3 h-3 text-red-500"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Registers</span>
                                        <p class="text-sm text-gray-600">Fastest memory, private to each thread, limited quantity.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-orange-100 rounded-full mr-2 mt-1">
                                        <i data-lucide="flame" class="w-3 h-3 text-orange-500"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Shared Memory</span>
                                        <p class="text-sm text-gray-600">Fast on-chip memory shared within a block, can be used for inter-thread communication.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-yellow-100 rounded-full mr-2 mt-1">
                                        <i data-lucide="flame" class="w-3 h-3 text-yellow-500"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Local Memory</span>
                                        <p class="text-sm text-gray-600">Private to each thread but physically located in global memory, used for register spilling.</p>
                                    </div>
                                </li>
                            </ul>
                        </div>
                        <div>
                            <h4 class="font-semibold mb-3">More Memory Types</h4>
                            <ul class="space-y-2">
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-1">
                                        <i data-lucide="database" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Global Memory</span>
                                        <p class="text-sm text-gray-600">Largest but slowest memory, accessible by all threads and persists for application lifetime.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-indigo-100 rounded-full mr-2 mt-1">
                                        <i data-lucide="bookmark" class="w-3 h-3 text-indigo-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Constant Memory</span>
                                        <p class="text-sm text-gray-600">Read-only memory with dedicated cache, best for values used by many threads.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-purple-100 rounded-full mr-2 mt-1">
                                        <i data-lucide="image" class="w-3 h-3 text-purple-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Texture Memory</span>
                                        <p class="text-sm text-gray-600">Read-only memory optimized for 2D spatial locality with specialized caching.</p>
                                    </div>
                                </li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="programming-model" class="mb-20">
            <div class="border-l-4 border-primary pl-4 mb-6">
                <h2 class="text-3xl font-bold">3. CUDA Programming Model</h2>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Thread Hierarchy</h3>
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mb-6">
                    <div class="grid grid-cols-1 lg:grid-cols-3 gap-8">
                        <div class="lg:col-span-1">
                            <div class="h-64 bg-gray-50 rounded-lg flex items-center justify-center mb-4">
                                <div class="text-center w-full p-4">
                                    <div class="mb-4">
                                        <div class="inline-block border-2 border-gray-400 p-1 rounded-md">
                                            <div class="bg-gray-200 p-1 font-semibold text-sm mb-1">Grid</div>
                                            <div class="grid grid-cols-2 gap-2">
                                                <div class="border-2 border-gray-400 p-1 rounded-sm">
                                                    <div class="bg-gray-200 text-sm mb-1">Block (0,0)</div>
                                                    <div class="grid grid-cols-2 gap-1">
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                    </div>
                                                </div>
                                                <div class="border-2 border-gray-400 p-1 rounded-sm">
                                                    <div class="bg-gray-200 text-sm mb-1">Block (0,1)</div>
                                                    <div class="grid grid-cols-2 gap-1">
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                    </div>
                                                </div>
                                                <div class="border-2 border-gray-400 p-1 rounded-sm">
                                                    <div class="bg-gray-200 text-sm mb-1">Block (1,0)</div>
                                                    <div class="grid grid-cols-2 gap-1">
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                    </div>
                                                </div>
                                                <div class="border-2 border-gray-400 p-1 rounded-sm">
                                                    <div class="bg-gray-200 text-sm mb-1">Block (1,1)</div>
                                                    <div class="grid grid-cols-2 gap-1">
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                        <div class="bg-primary w-6 h-4 rounded-sm mx-auto"></div>
                                                    </div>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    <div class="text-xs text-gray-600">Visualization of CUDA Thread Hierarchy</div>
                                </div>
                            </div>
                        </div>
                        <div class="lg:col-span-2">
                            <h4 class="font-semibold mb-3">Three-Level Hierarchy</h4>
                            <div class="grid grid-cols-1 md:grid-cols-3 gap-4 mb-4">
                                <div class="bg-gray-50 p-3 rounded-lg">
                                    <h5 class="font-medium text-sm mb-2 flex items-center">
                                        <div class="p-1 bg-primary/10 rounded-full mr-2">
                                            <i data-lucide="square" class="w-3 h-3 text-primary"></i>
                                        </div>
                                        Thread
                                    </h5>
                                    <p class="text-sm text-gray-600">The smallest execution unit. Each thread executes the same kernel function but typically operates on different data.</p>
                                    <div class="mt-2 p-2 bg-white rounded-md">
                                        <code class="text-xs font-geist-mono">threadIdx.x, threadIdx.y, threadIdx.z</code>
                                    </div>
                                </div>
                                <div class="bg-gray-50 p-3 rounded-lg">
                                    <h5 class="font-medium text-sm mb-2 flex items-center">
                                        <div class="p-1 bg-primary/10 rounded-full mr-2">
                                            <i data-lucide="grid" class="w-3 h-3 text-primary"></i>
                                        </div>
                                        Block
                                    </h5>
                                    <p class="text-sm text-gray-600">A group of threads that can cooperate via shared memory and synchronize execution.</p>
                                    <div class="mt-2 p-2 bg-white rounded-md">
                                        <code class="text-xs font-geist-mono">blockIdx.x, blockIdx.y, blockIdx.z</code>
                                    </div>
                                </div>
                                <div class="bg-gray-50 p-3 rounded-lg">
                                    <h5 class="font-medium text-sm mb-2 flex items-center">
                                        <div class="p-1 bg-primary/10 rounded-full mr-2">
                                            <i data-lucide="layout-grid" class="w-3 h-3 text-primary"></i>
                                        </div>
                                        Grid
                                    </h5>
                                    <p class="text-sm text-gray-600">A collection of blocks that execute the same kernel. Blocks within a grid run independently.</p>
                                    <div class="mt-2 p-2 bg-white rounded-md">
                                        <code class="text-xs font-geist-mono">gridDim.x, gridDim.y, gridDim.z</code>
                                    </div>
                                </div>
                            </div>
                            <div class="bg-gray-50 p-4 rounded-lg">
                                <h5 class="font-medium text-sm mb-2">Important Thread Characteristics</h5>
                                <ul class="space-y-2 text-sm">
                                    <li class="flex items-start">
                                        <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                            <i data-lucide="check" class="w-3 h-3 text-primary"></i>
                                        </div>
                                        <span>Threads within a block can synchronize and share data</span>
                                    </li>
                                    <li class="flex items-start">
                                        <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                            <i data-lucide="check" class="w-3 h-3 text-primary"></i>
                                        </div>
                                        <span>Threads in different blocks cannot directly synchronize</span>
                                    </li>
                                    <li class="flex items-start">
                                        <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                            <i data-lucide="check" class="w-3 h-3 text-primary"></i>
                                        </div>
                                        <span>Blocks are scheduled independently on available SMs</span>
                                    </li>
                                    <li class="flex items-start">
                                        <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                            <i data-lucide="check" class="w-3 h-3 text-primary"></i>
                                        </div>
                                        <span>Thread blocks should be independent, executable in any order</span>
                                    </li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                    <h4 class="font-semibold mb-4">Thread Block Clusters (Compute Capability 9.0+)</h4>
                    <p class="text-sm mb-4">With NVIDIA Compute Capability 9.0, an optional level of hierarchy called Thread Block Clusters is available. Thread blocks in a cluster are guaranteed to be co-scheduled on a GPU Processing Cluster (GPC), similar to how threads in a thread block are co-scheduled on a streaming multiprocessor.</p>
                    <div class="p-3 bg-gray-50 rounded-lg">
                        <div class="flex items-center mb-2">
                            <div class="p-1 bg-primary/10 rounded-full mr-2">
                                <i data-lucide="lightbulb" class="w-4 h-4 text-primary"></i>
                            </div>
                            <span class="font-medium text-sm">Benefits</span>
                        </div>
                        <ul class="space-y-1 ml-7 list-disc text-sm text-gray-700">
                            <li>Enhanced collaboration between thread blocks</li>
                            <li>Access to distributed shared memory across blocks</li>
                            <li>Improved scaling for complex algorithms</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Kernel Functions</h3>
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 mb-6">
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-3">Definition & Characteristics</h4>
                        <p class="text-sm mb-4">CUDA kernel functions are C++ functions that execute on the GPU in parallel by multiple CUDA threads.</p>
                        <div class="space-y-4">
                            <div class="flex items-start">
                                <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                    <i data-lucide="code" class="w-4 h-4 text-primary"></i>
                                </div>
                                <div>
                                    <h5 class="text-sm font-medium mb-1">Declaration</h5>
                                    <p class="text-sm text-gray-600">Defined using the <code class="font-geist-mono text-xs bg-gray-100 px-1 py-0.5 rounded">__global__</code> qualifier. Must have <code class="font-geist-mono text-xs bg-gray-100 px-1 py-0.5 rounded">void</code> return type.</p>
                                </div>
                            </div>
                            <div class="flex items-start">
                                <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                    <i data-lucide="play" class="w-4 h-4 text-primary"></i>
                                </div>
                                <div>
                                    <h5 class="text-sm font-medium mb-1">Execution</h5>
                                    <p class="text-sm text-gray-600">Executed on the device and called from the host. Devices with compute capability 5.0+ can call kernels from other kernels (Dynamic Parallelism).</p>
                                </div>
                            </div>
                            <div class="flex items-start">
                                <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                    <i data-lucide="rocket" class="w-4 h-4 text-primary"></i>
                                </div>
                                <div>
                                    <h5 class="text-sm font-medium mb-1">Launch Syntax</h5>
                                    <p class="text-sm text-gray-600">Uses the <code class="font-geist-mono text-xs bg-gray-100 px-1 py-0.5 rounded"><<<...>>></code> execution configuration syntax to specify thread and block dimensions.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-3">Kernel Example</h4>
                        <div class="bg-gray-800 text-gray-100 p-4 rounded-lg mb-4 overflow-x-auto">
                            <pre class="font-geist-mono text-xs leading-relaxed"><span class="text-blue-400">__global__</span> <span class="text-purple-400">void</span> <span class="text-green-400">vectorAdd</span>(<span class="text-purple-400">float</span>* A, <span class="text-purple-400">float</span>* B, <span class="text-purple-400">float</span>* C, <span class="text-purple-400">int</span> numElements) {
    <span class="text-purple-400">int</span> i = blockDim.x * blockIdx.x + threadIdx.x;
    
    <span class="text-blue-400">if</span> (i < numElements) {
        C[i] = A[i] + B[i];
    }
}

<span class="text-green-400">// Host code</span>
<span class="text-purple-400">int</span> <span class="text-green-400">main</span>() {
    <span class="text-green-400">// Calculate grid and block dimensions</span>
    <span class="text-purple-400">int</span> threadsPerBlock = 256;
    <span class="text-purple-400">int</span> blocksPerGrid = (numElements + threadsPerBlock - 1) / threadsPerBlock;
    
    <span class="text-green-400">// Launch kernel</span>
    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, numElements);
    
    <span class="text-green-400">// Wait for GPU to finish</span>
    cudaDeviceSynchronize();
}</pre>
                        </div>
                        <div class="bg-yellow-50 p-3 rounded-lg border border-yellow-100">
                            <div class="flex items-start">
                                <div class="p-1 bg-yellow-100 rounded-full mr-2 mt-0">
                                    <i data-lucide="alertTriangle" class="w-3 h-3 text-yellow-600"></i>
                                </div>
                                <div>
                                    <h5 class="text-sm font-medium text-yellow-800">Key Points</h5>
                                    <ul class="mt-1 text-xs space-y-1 text-yellow-700">
                                        <li> Each thread computes one element of the output</li>
                                        <li> Thread index calculation handles arbitrary vector sizes</li>
                                        <li> Boundary check ensures no out-of-bounds access</li>
                                        <li> Kernel launch specifies execution configuration</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Memory Management</h3>
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mb-6">
                    <div class="grid grid-cols-1 lg:grid-cols-2 gap-8">
                        <div>
                            <h4 class="font-semibold mb-3">Basic Memory Operations</h4>
                            <div class="bg-gray-50 p-4 rounded-lg mb-4">
                                <h5 class="font-medium text-sm mb-2">Allocation</h5>
                                <div class="bg-gray-800 text-white p-3 rounded font-geist-mono text-xs mb-2 overflow-x-auto">
                                    <pre>// Allocate memory on device
cudaError_t cudaMalloc(void** devPtr, size_t size);</pre>
                                </div>
                                <p class="text-xs text-gray-600">Allocates linear memory on the device and returns a pointer in <code class="font-geist-mono text-xs bg-gray-100 px-1 py-0.5 rounded">devPtr</code>.</p>
                            </div>
                            
                            <div class="bg-gray-50 p-4 rounded-lg mb-4">
                                <h5 class="font-medium text-sm mb-2">Data Transfer</h5>
                                <div class="bg-gray-800 text-white p-3 rounded font-geist-mono text-xs mb-2 overflow-x-auto">
                                    <pre>// Copy from host to device or device to host
cudaError_t cudaMemcpy(void* dst, const void* src, 
               size_t count, cudaMemcpyKind kind);</pre>
                                </div>
                                <p class="text-xs text-gray-600">Copies data between host and device. <code class="font-geist-mono text-xs bg-gray-100 px-1 py-0.5 rounded">kind</code> can be <code class="font-geist-mono text-xs bg-gray-100 px-1 py-0.5 rounded">cudaMemcpyHostToDevice</code> or <code class="font-geist-mono text-xs bg-gray-100 px-1 py-0.5 rounded">cudaMemcpyDeviceToHost</code>.</p>
                            </div>
                            
                            <div class="bg-gray-50 p-4 rounded-lg">
                                <h5 class="font-medium text-sm mb-2">Deallocation</h5>
                                <div class="bg-gray-800 text-white p-3 rounded font-geist-mono text-xs mb-2 overflow-x-auto">
                                    <pre>// Free device memory
cudaError_t cudaFree(void* devPtr);</pre>
                                </div>
                                <p class="text-xs text-gray-600">Frees memory allocated with <code class="font-geist-mono text-xs bg-gray-100 px-1 py-0.5 rounded">cudaMalloc</code>.</p>
                            </div>
                        </div>
                        
                        <div>
                            <h4 class="font-semibold mb-3">Advanced Memory Features</h4>
                            <div class="bg-gray-50 p-4 rounded-lg mb-4">
                                <h5 class="font-medium text-sm mb-2">Unified Memory</h5>
                                <div class="bg-gray-800 text-white p-3 rounded font-geist-mono text-xs mb-2 overflow-x-auto">
                                    <pre>// Allocate managed memory
cudaError_t cudaMallocManaged(void** devPtr, 
                      size_t size);</pre>
                                </div>
                                <p class="text-xs text-gray-600">Allocates memory that can be accessed from both CPU and GPU with automatic page migration.</p>
                            </div>
                            
                            <div class="bg-gray-50 p-4 rounded-lg mb-4">
                                <h5 class="font-medium text-sm mb-2">Pinned Memory</h5>
                                <div class="bg-gray-800 text-white p-3 rounded font-geist-mono text-xs mb-2 overflow-x-auto">
                                    <pre>// Allocate page-locked host memory
cudaError_t cudaMallocHost(void** ptr, size_t size);</pre>
                                </div>
                                <p class="text-xs text-gray-600">Allocates page-locked (non-swappable) memory on the host, which enables faster transfers to/from device.</p>
                            </div>
                            
                            <div class="bg-gray-50 p-4 rounded-lg">
                                <h5 class="font-medium text-sm mb-2">Asynchronous Operations</h5>
                                <div class="bg-gray-800 text-white p-3 rounded font-geist-mono text-xs mb-2 overflow-x-auto">
                                    <pre>// Asynchronous memory copy
cudaError_t cudaMemcpyAsync(void* dst, const void* src,
                    size_t count, cudaMemcpyKind kind,
                    cudaStream_t stream);</pre>
                                </div>
                                <p class="text-xs text-gray-600">Performs asynchronous copy, allowing overlapping of computation and data transfer when used with streams.</p>
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-4">
                    <div class="bg-white rounded-xl border border-gray-200 p-4 shadow-sm">
                        <div class="flex items-center mb-3">
                            <div class="p-2 bg-red-50 rounded-full mr-3">
                                <i data-lucide="alert-circle" class="w-4 h-4 text-red-500"></i>
                            </div>
                            <h4 class="font-medium text-sm">Common Pitfall</h4>
                        </div>
                        <p class="text-sm text-gray-600">Forgetting to free allocated memory can lead to memory leaks.</p>
                    </div>
                    
                    <div class="bg-white rounded-xl border border-gray-200 p-4 shadow-sm">
                        <div class="flex items-center mb-3">
                            <div class="p-2 bg-blue-50 rounded-full mr-3">
                                <i data-lucide="lightbulb" class="w-4 h-4 text-blue-500"></i>
                            </div>
                            <h4 class="font-medium text-sm">Best Practice</h4>
                        </div>
                        <p class="text-sm text-gray-600">Always check return values from CUDA API calls for error detection.</p>
                    </div>
                    
                    <div class="bg-white rounded-xl border border-gray-200 p-4 shadow-sm">
                        <div class="flex items-center mb-3">
                            <div class="p-2 bg-yellow-50 rounded-full mr-3">
                                <i data-lucide="alert-triangle" class="w-4 h-4 text-yellow-500"></i>
                            </div>
                            <h4 class="font-medium text-sm">Warning</h4>
                        </div>
                        <p class="text-sm text-gray-600">Excessive memory transfers between host and device can become a performance bottleneck.</p>
                    </div>
                    
                    <div class="bg-white rounded-xl border border-gray-200 p-4 shadow-sm">
                        <div class="flex items-center mb-3">
                            <div class="p-2 bg-green-50 rounded-full mr-3">
                                <i data-lucide="check-circle" class="w-4 h-4 text-green-500"></i>
                            </div>
                            <h4 class="font-medium text-sm">Tip</h4>
                        </div>
                        <p class="text-sm text-gray-600">Unified Memory simplifies code but may not always provide the best performance.</p>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">CUDA Program Structure</h3>
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                    <div class="grid grid-cols-1 lg:grid-cols-2 gap-8">
                        <div>
                            <h4 class="font-semibold mb-3">Host-Device Programming Model</h4>
                            <p class="text-sm mb-4">CUDA uses a heterogeneous programming model where both the CPU (host) and GPU (device) are utilized. The host manages memory for both and launches kernels for execution on the device.</p>
                            <div class="h-64 bg-gray-100 rounded-lg flex justify-center items-center p-4 mb-4">
                                <div class="grid grid-cols-2 gap-6 w-full max-w-md">
                                    <div class="bg-white p-3 rounded-md shadow-sm text-center">
                                        <div class="font-medium mb-2">Host (CPU)</div>
                                        <ul class="text-xs text-left space-y-2">
                                            <li class="flex items-start">
                                                <div class="p-1 bg-blue-100 rounded-full mr-1 mt-0">
                                                    <i data-lucide="chevron-right" class="w-2 h-2 text-blue-600"></i>
                                                </div>
                                                <span>Initialize data</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-blue-100 rounded-full mr-1 mt-0">
                                                    <i data-lucide="chevron-right" class="w-2 h-2 text-blue-600"></i>
                                                </div>
                                                <span>Allocate memory</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-blue-100 rounded-full mr-1 mt-0">
                                                    <i data-lucide="chevron-right" class="w-2 h-2 text-blue-600"></i>
                                                </div>
                                                <span>Transfer data to device</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-blue-100 rounded-full mr-1 mt-0">
                                                    <i data-lucide="chevron-right" class="w-2 h-2 text-blue-600"></i>
                                                </div>
                                                <span>Launch kernels</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-blue-100 rounded-full mr-1 mt-0">
                                                    <i data-lucide="chevron-right" class="w-2 h-2 text-blue-600"></i>
                                                </div>
                                                <span>Transfer results back</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-blue-100 rounded-full mr-1 mt-0">
                                                    <i data-lucide="chevron-right" class="w-2 h-2 text-blue-600"></i>
                                                </div>
                                                <span>Process results</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-blue-100 rounded-full mr-1 mt-0">
                                                    <i data-lucide="chevron-right" class="w-2 h-2 text-blue-600"></i>
                                                </div>
                                                <span>Free memory</span>
                                            </li>
                                        </ul>
                                    </div>
                                    <div class="bg-white p-3 rounded-md shadow-sm text-center">
                                        <div class="font-medium mb-2">Device (GPU)</div>
                                        <ul class="text-xs text-left space-y-2">
                                            <li class="flex items-start">
                                                <div class="p-1 bg-primary/10 rounded-full mr-1 mt-0">
                                                    <i data-lucide="chevron-right" class="w-2 h-2 text-primary"></i>
                                                </div>
                                                <span>Execute kernel code</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-primary/10 rounded-full mr-1 mt-0">
                                                    <i data-lucide="chevron-right" class="w-2 h-2 text-primary"></i>
                                                </div>
                                                <span>Parallel processing</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-primary/10 rounded-full mr-1 mt-0">
                                                    <i data-lucide="chevron-right" class="w-2 h-2 text-primary"></i>
                                                </div>
                                                <span>Thread cooperation</span>
                                            </li>
                                            <li class="flex items-start">
                                                <div class="p-1 bg-primary/10 rounded-full mr-1 mt-0">
                                                    <i data-lucide="chevron-right" class="w-2 h-2 text-primary"></i>
                                                </div>
                                                <span>Memory operations</span>
                                            </li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                            <div class="bg-blue-50 p-3 rounded-lg border border-blue-100">
                                <div class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                        <i data-lucide="info" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <p class="text-xs text-blue-800">The CUDA compiler (nvcc) separates host and device code. Device code is compiled for the GPU, while host code is compiled with a standard C/C++ compiler.</p>
                                </div>
                            </div>
                        </div>
                        <div>
                            <h4 class="font-semibold mb-3">Typical CUDA Program Flow</h4>
                            <div class="bg-gray-800 text-gray-100 p-4 rounded-lg mb-4 overflow-x-auto">
                                <pre class="font-geist-mono text-xs leading-loose"><span class="text-green-400">// A typical CUDA program structure</span>
<span class="text-purple-400">int</span> <span class="text-blue-400">main</span>() {
    <span class="text-green-400">// 1. Declare and allocate host (CPU) memory</span>
    <span class="text-purple-400">float</span>* h_A = (<span class="text-purple-400">float</span>*)malloc(size);
    <span class="text-purple-400">float</span>* h_B = (<span class="text-purple-400">float</span>*)malloc(size);
    <span class="text-purple-400">float</span>* h_C = (<span class="text-purple-400">float</span>*)malloc(size);
    
    <span class="text-green-400">// 2. Initialize host data</span>
    <span class="text-blue-400">for</span> (<span class="text-purple-400">int</span> i = 0; i < numElements; i++) {
        h_A[i] = rand() / (<span class="text-purple-400">float</span>)RAND_MAX;
        h_B[i] = rand() / (<span class="text-purple-400">float</span>)RAND_MAX;
    }
    
    <span class="text-green-400">// 3. Allocate device (GPU) memory</span>
    <span class="text-purple-400">float</span>* d_A, *d_B, *d_C;
    cudaMalloc((<span class="text-purple-400">void</span>**)&d_A, size);
    cudaMalloc((<span class="text-purple-400">void</span>**)&d_B, size);
    cudaMalloc((<span class="text-purple-400">void</span>**)&d_C, size);
    
    <span class="text-green-400">// 4. Transfer data from host to device</span>
    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);
    
    <span class="text-green-400">// 5. Set execution configuration</span>
    <span class="text-purple-400">int</span> threadsPerBlock = 256;
    <span class="text-purple-400">int</span> blocksPerGrid = (numElements + 
                       threadsPerBlock - 1) / 
                       threadsPerBlock;
    
    <span class="text-green-400">// 6. Launch kernel</span>
    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(
                d_A, d_B, d_C, numElements);
    
    <span class="text-green-400">// 7. Transfer results from device to host</span>
    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);
    
    <span class="text-green-400">// 8. Free device memory</span>
    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);
    
    <span class="text-green-400">// 9. Free host memory</span>
    free(h_A); free(h_B); free(h_C);
    
    <span class="text-purple-400">return</span> 0;
}</pre>
                            </div>
                            <div class="bg-gray-50 p-4 rounded-lg">
                                <h5 class="font-medium text-sm mb-3">Key Phases</h5>
                                <ol class="space-y-2 pl-5 text-sm">
                                    <li>
                                        <span class="font-medium">Initialization:</span>
                                        <span class="text-gray-600">Setup host data and allocate memory</span>
                                    </li>
                                    <li>
                                        <span class="font-medium">Data Transfer:</span>
                                        <span class="text-gray-600">Copy input data to device</span>
                                    </li>
                                    <li>
                                        <span class="font-medium">Execution:</span>
                                        <span class="text-gray-600">Launch kernel for parallel computation</span>
                                    </li>
                                    <li>
                                        <span class="font-medium">Result Retrieval:</span>
                                        <span class="text-gray-600">Copy results back to host</span>
                                    </li>
                                    <li>
                                        <span class="font-medium">Cleanup:</span>
                                        <span class="text-gray-600">Free allocated memory</span>
                                    </li>
                                </ol>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Synchronization</h3>
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                    <div class="grid grid-cols-1 lg:grid-cols-2 gap-8">
                        <div>
                            <h4 class="font-semibold mb-3">Host Synchronization</h4>
                            <div class="bg-gray-50 p-4 rounded-lg mb-4">
                                <h5 class="font-medium text-sm mb-2">Global Synchronization</h5>
                                <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mb-2 overflow-x-auto">
                                    <pre>cudaDeviceSynchronize();</pre>
                                </div>
                                <p class="text-xs text-gray-600">Blocks the host until all preceding CUDA tasks on the device are complete.</p>
                            </div>
                            
                            <div class="bg-gray-50 p-4 rounded-lg mb-4">
                                <h5 class="font-medium text-sm mb-2">Stream Synchronization</h5>
                                <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mb-2 overflow-x-auto">
                                    <pre>cudaStreamSynchronize(stream);</pre>
                                </div>
                                <p class="text-xs text-gray-600">Blocks the host until all operations in the specified stream have completed.</p>
                            </div>
                            
                            <div class="bg-gray-50 p-4 rounded-lg mb-4">
                                <h5 class="font-medium text-sm mb-2">Event-Based Synchronization</h5>
                                <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mb-2 overflow-x-auto">
                                    <pre>cudaEvent_t event;
cudaEventCreate(&event);
cudaEventRecord(event, stream);
cudaEventSynchronize(event);</pre>
                                </div>
                                <p class="text-xs text-gray-600">Records an event and blocks until the event is recorded. Used for fine-grained synchronization.</p>
                            </div>
                        </div>
                        
                        <div>
                            <h4 class="font-semibold mb-3">Device Synchronization</h4>
                            <div class="bg-gray-50 p-4 rounded-lg mb-4">
                                <h5 class="font-medium text-sm mb-2">Block Synchronization</h5>
                                <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mb-2 overflow-x-auto">
                                    <pre>__syncthreads();</pre>
                                </div>
                                <p class="text-xs text-gray-600">Synchronizes all threads within a block. Acts as a barrier where all threads must wait before any can proceed.</p>
                            </div>
                            
                            <div class="bg-gray-50 p-4 rounded-lg mb-4">
                                <h5 class="font-medium text-sm mb-2">Warp Synchronization</h5>
                                <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mb-2 overflow-x-auto">
                                    <pre>__syncwarp();</pre>
                                </div>
                                <p class="text-xs text-gray-600">Synchronizes threads within a warp (32 threads). Useful for optimizing performance in compute capability 7.0+.</p>
                            </div>
                            
                            <div class="bg-gray-50 p-4 rounded-lg mb-4">
                                <h5 class="font-medium text-sm mb-2">Memory Fence Operations</h5>
                                <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mb-2 overflow-x-auto">
                                    <pre>__threadfence();         // Device-wide fence
__threadfence_block();    // Block-wide fence
__threadfence_system();   // System-wide fence</pre>
                                </div>
                                <p class="text-xs text-gray-600">Ensures memory operations are visible to other threads at different scopes.</p>
                            </div>
                        </div>
                    </div>
                    <div class="bg-yellow-50 p-4 rounded-lg border border-yellow-200 mt-4">
                        <div class="flex items-start">
                            <div class="p-1 bg-yellow-200 rounded-full mr-3 mt-1">
                                <i data-lucide="alert-triangle" class="w-4 h-4 text-yellow-600"></i>
                            </div>
                            <div>
                                <h5 class="font-medium text-sm mb-1 text-yellow-800">Important Considerations</h5>
                                <ul class="text-sm text-yellow-700 space-y-1">
                                    <li> Excessive synchronization can limit parallelism and hurt performance</li>
                                    <li> Threads in different blocks cannot directly synchronize with each other</li>
                                    <li> Streams enable asynchronous operations that can overlap computation and data transfer</li>
                                    <li> Consider cooperative groups for more flexible synchronization patterns (in newer CUDA versions)</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="optimization" class="mb-20">
            <div class="border-l-4 border-primary pl-4 mb-6">
                <h2 class="text-3xl font-bold">4. Optimizing CUDA Performance</h2>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Memory Coalescing</h3>
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 mb-6">
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-3">What is Memory Coalescing?</h4>
                        <p class="text-sm mb-4">Memory coalescing is an optimization technique that maximizes global memory bandwidth by combining multiple memory accesses from threads within a warp into as few transactions as possible.</p>
                        
                        <div class="bg-gray-50 p-4 rounded-lg mb-4">
                            <h5 class="font-medium text-sm mb-2">Benefits</h5>
                            <ul class="space-y-2 text-sm">
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <span>Significantly improved memory bandwidth utilization</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <span>Reduced number of memory transactions</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <span>Better overall kernel performance</span>
                                </li>
                            </ul>
                        </div>
                        
                        <div class="bg-gray-50 p-4 rounded-lg">
                            <h5 class="font-medium text-sm mb-2">Key Requirements</h5>
                            <ul class="space-y-2 text-sm">
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <span>Consecutive threads access consecutive memory locations</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <span>Memory accesses are aligned to appropriate boundaries</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <span>Data is arranged to support access patterns</span>
                                </li>
                            </ul>
                        </div>
                    </div>
                    
                    <div>
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mb-6">
                            <h4 class="font-semibold mb-3">Coalesced vs. Uncoalesced Access</h4>
                            <div class="h-64 bg-gray-50 rounded-lg flex items-center justify-center p-4">
                                <div class="text-center w-full">
                                    <div class="flex flex-col space-y-4">
                                        <div>
                                            <h5 class="text-sm font-medium mb-2">Coalesced Access (Efficient)</h5>
                                            <div class="flex justify-center mb-1">
                                                <div class="flex">
                                                    <div class="w-8 h-8 bg-primary rounded-sm border border-gray-200 flex items-center justify-center text-white text-xs">T0</div>
                                                    <div class="w-8 h-8 bg-primary rounded-sm border border-gray-200 flex items-center justify-center text-white text-xs">T1</div>
                                                    <div class="w-8 h-8 bg-primary rounded-sm border border-gray-200 flex items-center justify-center text-white text-xs">T2</div>
                                                    <div class="w-8 h-8 bg-primary rounded-sm border border-gray-200 flex items-center justify-center text-white text-xs">T3</div>
                                                </div>
                                            </div>
                                            <div class="flex justify-center">
                                                <i data-lucide="arrow-down" class="w-4 h-4 text-green-600"></i>
                                                <i data-lucide="arrow-down" class="w-4 h-4 text-green-600"></i>
                                                <i data-lucide="arrow-down" class="w-4 h-4 text-green-600"></i>
                                                <i data-lucide="arrow-down" class="w-4 h-4 text-green-600"></i>
                                            </div>
                                            <div class="flex justify-center">
                                                <div class="flex">
                                                    <div class="w-8 h-8 bg-blue-100 rounded-sm border border-gray-200 flex items-center justify-center text-xs">M0</div>
                                                    <div class="w-8 h-8 bg-blue-100 rounded-sm border border-gray-200 flex items-center justify-center text-xs">M1</div>
                                                    <div class="w-8 h-8 bg-blue-100 rounded-sm border border-gray-200 flex items-center justify-center text-xs">M2</div>
                                                    <div class="w-8 h-8 bg-blue-100 rounded-sm border border-gray-200 flex items-center justify-center text-xs">M3</div>
                                                </div>
                                            </div>
                                            <div class="mt-1 text-xs text-green-600">1 Memory Transaction</div>
                                        </div>
                                        
                                        <div>
                                            <h5 class="text-sm font-medium mb-2">Uncoalesced Access (Inefficient)</h5>
                                            <div class="flex justify-center mb-1">
                                                <div class="flex">
                                                    <div class="w-8 h-8 bg-primary rounded-sm border border-gray-200 flex items-center justify-center text-white text-xs">T0</div>
                                                    <div class="w-8 h-8 bg-primary rounded-sm border border-gray-200 flex items-center justify-center text-white text-xs">T1</div>
                                                    <div class="w-8 h-8 bg-primary rounded-sm border border-gray-200 flex items-center justify-center text-white text-xs">T2</div>
                                                    <div class="w-8 h-8 bg-primary rounded-sm border border-gray-200 flex items-center justify-center text-white text-xs">T3</div>
                                                </div>
                                            </div>
                                            <div class="flex justify-center">
                                                <div class="flex">
                                                    <i data-lucide="arrow-down" class="w-4 h-4 text-red-600"></i>
                                                    <div class="w-6"></div>
                                                    <i data-lucide="arrow-down" class="w-4 h-4 text-red-600"></i>
                                                    <div class="w-6"></div>
                                                    <i data-lucide="arrow-down" class="w-4 h-4 text-red-600"></i>
                                                    <div class="w-6"></div>
                                                    <i data-lucide="arrow-down" class="w-4 h-4 text-red-600"></i>
                                                </div>
                                            </div>
                                            <div class="flex justify-center">
                                                <div class="flex">
                                                    <div class="w-8 h-8 bg-blue-100 rounded-sm border border-gray-200 flex items-center justify-center text-xs">M0</div>
                                                    <div class="w-8 h-8 bg-blue-100 rounded-sm border border-gray-200 flex items-center justify-center text-xs">M4</div>
                                                    <div class="w-8 h-8 bg-blue-100 rounded-sm border border-gray-200 flex items-center justify-center text-xs">M8</div>
                                                    <div class="w-8 h-8 bg-blue-100 rounded-sm border border-gray-200 flex items-center justify-center text-xs">M12</div>
                                                </div>
                                            </div>
                                            <div class="mt-1 text-xs text-red-600">4 Memory Transactions</div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                            <h4 class="font-semibold mb-3">Achieving Coalescing</h4>
                            <div class="bg-gray-50 p-3 rounded-lg mb-3">
                                <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mb-2 overflow-x-auto">
                                    <pre><span class="text-green-400">// Coalesced access (good) - threads access consecutive elements</span>
<span class="text-blue-400">__global__</span> <span class="text-purple-400">void</span> <span class="text-blue-400">coalesced</span>(<span class="text-purple-400">float</span>* data) {
    <span class="text-purple-400">int</span> idx = blockIdx.x * blockDim.x + threadIdx.x;
    data[idx] = data[idx] * 2.0f;
}

<span class="text-green-400">// Uncoalesced access (bad) - threads access strided elements</span>
<span class="text-blue-400">__global__</span> <span class="text-purple-400">void</span> <span class="text-blue-400">uncoalesced</span>(<span class="text-purple-400">float</span>* data, <span class="text-purple-400">int</span> stride) {
    <span class="text-purple-400">int</span> idx = (blockIdx.x * blockDim.x + threadIdx.x) * stride;
    data[idx] = data[idx] * 2.0f;
}</pre>
                                </div>
                            </div>
                            <div class="p-3 bg-blue-50 rounded-lg border border-blue-100">
                                <div class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="lightbulb" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium text-blue-800 mb-1">Tips</h5>
                                        <ul class="text-xs text-blue-700 space-y-1">
                                            <li> Use AoS (Array of Structures) vs SoA (Structure of Arrays) appropriately</li>
                                            <li> Pad data structures to align to memory boundaries</li>
                                            <li> Consider using shared memory for non-coalesced access patterns</li>
                                            <li> Transpose matrices to improve memory access patterns when needed</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Occupancy Optimization</h3>
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 mb-6">
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-3">What is Occupancy?</h4>
                        <p class="text-sm mb-4">Occupancy is the ratio of active warps per multiprocessor to the maximum possible active warps. Higher occupancy can help hide memory latency but doesn't always guarantee better performance.</p>
                        
                        <div class="flex items-center justify-center my-6">
                            <div class="relative w-64 h-64 rounded-full border-8 border-gray-200">
                                <div class="absolute top-0 left-0 w-full h-full rounded-full border-8 border-primary border-t-transparent transform -rotate-45"></div>
                                <div class="absolute top-0 left-0 w-full h-full flex items-center justify-center flex-col">
                                    <span class="text-4xl font-bold">75%</span>
                                    <span class="text-sm text-gray-600">Occupancy</span>
                                </div>
                            </div>
                        </div>
                        
                        <div class="bg-gray-50 p-4 rounded-lg">
                            <h5 class="font-medium text-sm mb-2">Factors Limiting Occupancy</h5>
                            <ul class="space-y-2 text-sm">
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="layers" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <span>Register usage per thread</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="database" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <span>Shared memory usage per block</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="grid" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <span>Block size and shape</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="cpu" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <span>Hardware limits of the SM</span>
                                </li>
                            </ul>
                        </div>
                    </div>
                    
                    <div>
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mb-6">
                            <h4 class="font-semibold mb-3">Optimization Strategies</h4>
                            <div class="space-y-4">
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="settings" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Manage Register Usage</h5>
                                        <p class="text-sm text-gray-600">Limit register usage with compiler options or function attributes:</p>
                                        <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mt-1 mb-1 overflow-x-auto">
                                            <pre><span class="text-green-400">// Compile with --maxrregcount=N flag</span>
<span class="text-green-400">// Or use launch bounds in code:</span>
<span class="text-blue-400">__global__ __launch_bounds__(256, 4)</span> <span class="text-purple-400">void</span> 
myKernel(...) { ... }</pre>
                                        </div>
                                        <p class="text-xs text-gray-600">Sets max threads per block (256) and min blocks per SM (4)</p>
                                    </div>
                                </div>
                                
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="settings" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Optimize Thread Block Size</h5>
                                        <p class="text-sm text-gray-600">Choose thread block dimensions that maximize occupancy:</p>
                                        <ul class="mt-1 ml-4 list-disc text-xs text-gray-600">
                                            <li>Use multiples of 32 threads (warp size)</li>
                                            <li>128-256 threads per block is often a good starting point</li>
                                            <li>Balance between having enough blocks for all SMs and enough threads for latency hiding</li>
                                        </ul>
                                    </div>
                                </div>
                                
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="settings" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Manage Shared Memory</h5>
                                        <p class="text-sm text-gray-600">Dynamic shared memory allocation can help balance usage:</p>
                                        <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mt-1 mb-1 overflow-x-auto">
                                            <pre><span class="text-blue-400">__global__</span> <span class="text-purple-400">void</span> <span class="text-blue-400">sharedMemKernel</span>(...) {
    <span class="text-blue-400">extern</span> <span class="text-blue-400">__shared__</span> <span class="text-purple-400">float</span> sharedData[];
    <span class="text-green-400">// Use shared memory</span>
}
<span class="text-green-400">// Launch with dynamic shared memory size</span>
sharedMemKernel<<<blocks, threads, sharedMemSize>>>(...)</pre>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                            <h4 class="font-semibold mb-3">Finding the Right Balance</h4>
                            <p class="text-sm mb-3">Occupancy is just one of many factors affecting performance. Sometimes lower occupancy with higher ILP (Instruction-Level Parallelism) can yield better results.</p>
                            <div class="p-3 bg-yellow-50 rounded-lg border border-yellow-100">
                                <div class="flex items-start">
                                    <div class="p-1 bg-yellow-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="lightbulb" class="w-3 h-3 text-yellow-700"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium text-yellow-800 mb-1">Performance Testing</h5>
                                        <p class="text-xs text-yellow-700">Always benchmark different configurations. Use the NVIDIA Occupancy Calculator or Nsight Compute to analyze occupancy and find optimal settings.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Shared Memory and Bank Conflicts</h3>
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 mb-6">
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-3">Shared Memory Benefits</h4>
                        <p class="text-sm mb-4">Shared memory is a programmable, on-chip cache available to all threads within a block. When used correctly, it can be significantly faster than global memory access.</p>
                        
                        <div class="bg-gray-50 p-4 rounded-lg mb-4">
                            <h5 class="font-medium text-sm mb-2">Key Advantages</h5>
                            <ul class="space-y-2 text-sm">
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="zap" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span>Much lower latency than global memory (up to 100x faster)</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="zap" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span>Enables efficient inter-thread communication</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="zap" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span>Can avoid redundant global memory accesses</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="zap" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span>Helps avoid uncoalesced global memory access patterns</span>
                                </li>
                            </ul>
                        </div>
                        
                        <div class="bg-gray-50 p-4 rounded-lg">
                            <h5 class="font-medium text-sm mb-2">Common Uses</h5>
                            <ul class="space-y-2 text-sm">
                                <li class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <span>Caching frequently accessed data</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <span>Matrix transposition</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <span>Convolution and stencil operations</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <span>Reduction algorithms</span>
                                </li>
                            </ul>
                        </div>
                    </div>
                    
                    <div>
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mb-6">
                            <h4 class="font-semibold mb-3">Bank Conflicts</h4>
                            <p class="text-sm mb-3">Shared memory is divided into equally-sized memory banks (typically 32). Bank conflicts occur when multiple threads within a warp try to access different addresses within the same bank simultaneously.</p>
                            
                            <div class="h-48 bg-gray-50 rounded-lg flex items-center justify-center p-4 mb-4">
                                <div class="text-center">
                                    <div class="grid grid-cols-8 gap-1 mb-2">
                                        <div class="flex flex-col">
                                            <span class="text-xs text-gray-500 mb-1">Bank 0</span>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm"></div>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm mt-1"></div>
                                        </div>
                                        <div class="flex flex-col">
                                            <span class="text-xs text-gray-500 mb-1">Bank 1</span>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm"></div>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm mt-1"></div>
                                        </div>
                                        <div class="flex flex-col">
                                            <span class="text-xs text-gray-500 mb-1">Bank 2</span>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm"></div>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm mt-1"></div>
                                        </div>
                                        <div class="flex flex-col">
                                            <span class="text-xs text-gray-500 mb-1">Bank 3</span>
                                            <div class="w-8 h-6 bg-blue-100 border border-red-400 rounded-sm"></div>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm mt-1"></div>
                                        </div>
                                        <div class="flex flex-col">
                                            <span class="text-xs text-gray-500 mb-1">Bank 4</span>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm"></div>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm mt-1"></div>
                                        </div>
                                        <div class="flex flex-col">
                                            <span class="text-xs text-gray-500 mb-1">Bank 5</span>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm"></div>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm mt-1"></div>
                                        </div>
                                        <div class="flex flex-col">
                                            <span class="text-xs text-gray-500 mb-1">Bank 6</span>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm"></div>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm mt-1"></div>
                                        </div>
                                        <div class="flex flex-col">
                                            <span class="text-xs text-gray-500 mb-1">Bank 7</span>
                                            <div class="w-8 h-6 bg-blue-100 border border-red-400 rounded-sm"></div>
                                            <div class="w-8 h-6 bg-blue-100 border border-blue-200 rounded-sm mt-1"></div>
                                        </div>
                                    </div>
                                    <div class="flex items-center justify-center">
                                        <div class="flex items-center mr-4">
                                            <div class="w-3 h-3 border border-red-400 mr-1"></div>
                                            <span class="text-xs">Bank Conflict</span>
                                        </div>
                                        <div class="flex items-center">
                                            <div class="w-3 h-3 border border-blue-200 mr-1"></div>
                                            <span class="text-xs">No Conflict</span>
                                        </div>
                                    </div>
                                    <p class="text-xs text-gray-600 mt-2">Multiple threads accessing different words in the same bank</p>
                                </div>
                            </div>
                            
                            <div class="bg-gray-50 p-3 rounded-lg">
                                <h5 class="font-medium text-sm mb-2">Impact of Bank Conflicts</h5>
                                <ul class="space-y-1 text-sm">
                                    <li class="flex items-start">
                                        <div class="p-1 bg-red-100 rounded-full mr-2 mt-0">
                                            <i data-lucide="x" class="w-3 h-3 text-red-600"></i>
                                        </div>
                                        <span>Serialized memory accesses</span>
                                    </li>
                                    <li class="flex items-start">
                                        <div class="p-1 bg-red-100 rounded-full mr-2 mt-0">
                                            <i data-lucide="x" class="w-3 h-3 text-red-600"></i>
                                        </div>
                                        <span>Reduced effective bandwidth</span>
                                    </li>
                                    <li class="flex items-start">
                                        <div class="p-1 bg-red-100 rounded-full mr-2 mt-0">
                                            <i data-lucide="x" class="w-3 h-3 text-red-600"></i>
                                        </div>
                                        <span>Potential performance degradation</span>
                                    </li>
                                </ul>
                            </div>
                        </div>
                        
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                            <h4 class="font-semibold mb-3">Avoiding Bank Conflicts</h4>
                            <div class="space-y-4">
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="shuffle" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Padding</h5>
                                        <p class="text-sm text-gray-600">Add padding to shared memory arrays to avoid stride access to the same bank:</p>
                                        <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mt-1 overflow-x-auto">
                                            <pre><span class="text-blue-400">__shared__</span> <span class="text-purple-400">float</span> sdata[BLOCK_SIZE + 1]; <span class="text-green-400">// Add padding</span></pre>
                                        </div>
                                    </div>
                                </div>
                                
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="shuffle" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Access Patterns</h5>
                                        <p class="text-sm text-gray-600">Design access patterns to avoid conflicts, especially for matrix operations:</p>
                                        <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mt-1 overflow-x-auto">
                                            <pre><span class="text-green-400">// Instead of this (potential conflicts):</span>
<span class="text-purple-400">float</span> val = sdata[ty][tx];

<span class="text-green-400">// Use this (avoids conflicts in matrix transpose):</span>
<span class="text-purple-400">float</span> val = sdata[tx][ty];</pre>
                                        </div>
                                    </div>
                                </div>
                                
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="shuffle" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Broadcast Mode</h5>
                                        <p class="text-sm text-gray-600">When all threads in a warp access the same shared memory address, the hardware broadcasts the value with no conflicts.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Avoiding Warp Divergence</h3>
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mb-6">
                    <div class="grid grid-cols-1 lg:grid-cols-2 gap-8">
                        <div>
                            <h4 class="font-semibold mb-3">Understanding Warp Divergence</h4>
                            <p class="text-sm mb-4">Warp divergence occurs when threads within the same warp take different execution paths due to conditional statements (if, switch, etc.). Since threads in a warp execute in SIMT (Single Instruction, Multiple Thread) fashion, divergent paths are serialized, reducing performance.</p>
                            
                            <div class="h-64 bg-gray-50 rounded-lg flex items-center justify-center p-4 mb-4">
                                <div class="w-full max-w-md">
                                    <div class="mb-6">
                                        <h5 class="text-sm font-medium text-center mb-2">Divergent Warp Execution</h5>
                                        <div class="relative">
                                            <div class="flex mb-2">
                                                <div class="w-full bg-primary h-8 rounded-t-md flex items-center justify-center text-white text-xs">
                                                    32 Threads in a Warp
                                                </div>
                                            </div>
                                            <div class="flex">
                                                <div class="w-1/2 bg-blue-500 h-24 rounded-bl-md flex items-center justify-center text-white text-xs p-2">
                                                    16 Threads<br/>if (x &lt; threshold)
                                                </div>
                                                <div class="w-1/2 bg-red-500 h-24 rounded-br-md flex items-center justify-center text-white text-xs p-2">
                                                    16 Threads<br/>else
                                                </div>
                                            </div>
                                            <div class="absolute top-10 left-1/2 transform -translate-x-1/2">
                                                <i data-lucide="git-branch" class="w-6 h-6 text-gray-700"></i>
                                            </div>
                                        </div>
                                        <div class="mt-2 text-center text-xs text-red-600">Performance penalty: paths are serialized</div>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="bg-red-50 p-3 rounded-lg">
                                <div class="flex items-start">
                                    <div class="p-1 bg-red-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="alert-triangle" class="w-3 h-3 text-red-600"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium text-red-800">Performance Impact</h5>
                                        <p class="text-xs text-red-700">When threads in a warp diverge, the different execution paths are serialized. The total runtime becomes the sum of the time taken by each path, slowing down execution considerably.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                        <div>
                            <h4 class="font-semibold mb-3">Minimizing Divergence</h4>
                            <div class="space-y-4">
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="folder-tree" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Avoid Thread-ID Based Conditionals</h5>
                                        <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mt-1 mb-1 overflow-x-auto">
                                            <pre><span class="text-green-400">// Bad: divergence based on threadIdx</span>
<span class="text-blue-400">if</span> (threadIdx.x % 2 == 0) {
    <span class="text-green-400">// Even threads do this</span>
} <span class="text-blue-400">else</span> {
    <span class="text-green-400">// Odd threads do this</span>
}

<span class="text-green-400">// Better: coherent warps</span>
<span class="text-blue-400">if</span> (blockIdx.x % 2 == 0) {
    <span class="text-green-400">// Entire warps do this</span>
} <span class="text-blue-400">else</span> {
    <span class="text-green-400">// Entire warps do this</span>
}</pre>
                                        </div>
                                    </div>
                                </div>
                                
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="folder-tree" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Avoid Short Conditional Branches</h5>
                                        <p class="text-sm text-gray-600">For very short code paths, sometimes doing both computations and selecting the result is faster than branching:</p>
                                        <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mt-1 mb-1 overflow-x-auto">
                                            <pre><span class="text-green-400">// Instead of branching:</span>
<span class="text-blue-400">if</span> (condition) {
    result = a + b;
} <span class="text-blue-400">else</span> {
    result = a - b;
}

<span class="text-green-400">// Use branch-free code:</span>
<span class="text-purple-400">float</span> val1 = a + b;
<span class="text-purple-400">float</span> val2 = a - b;
result = condition ? val1 : val2;</pre>
                                        </div>
                                    </div>
                                </div>
                                
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="folder-tree" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Thread/Data Reorganization</h5>
                                        <p class="text-sm text-gray-600">Restructure data or thread assignments to ensure threads in the same warp follow the same path:</p>
                                        <ul class="mt-1 ml-4 list-disc text-xs text-gray-600">
                                            <li>Sort data to group similar items</li>
                                            <li>Assign threads to work on data that requires similar processing</li>
                                            <li>Process different cases in separate kernel launches</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="bg-blue-50 p-3 rounded-lg mt-4">
                                <div class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="info" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium text-blue-800">Important Note</h5>
                                        <p class="text-xs text-blue-700">While inter-warp divergence (different warps taking different paths) is not a performance concern, intra-warp divergence (within a single warp) should be minimized whenever possible.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Common Pitfalls and Debugging</h3>
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 mb-6">
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-3">Common CUDA Errors</h4>
                        <div class="space-y-4">
                            <div class="bg-red-50 p-3 rounded-lg">
                                <div class="flex">
                                    <div class="p-1 bg-red-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="alert-triangle" class="w-3 h-3 text-red-600"></i>
                                    </div>
                                    <h5 class="text-sm font-medium text-red-800">Memory Management Issues</h5>
                                </div>
                                <ul class="mt-1 ml-6 list-disc text-xs text-red-700">
                                    <li>Unbalanced allocations and deallocations (memory leaks)</li>
                                    <li>Using device pointers on host or vice versa</li>
                                    <li>Out-of-bounds memory access</li>
                                    <li>Using unallocated memory</li>
                                </ul>
                                <div class="mt-2">
                                    <p class="text-xs text-red-700"><span class="font-medium">Solution:</span> Always check CUDA API return values and pair cudaMalloc/cudaFree calls.</p>
                                </div>
                            </div>
                            
                            <div class="bg-red-50 p-3 rounded-lg">
                                <div class="flex">
                                    <div class="p-1 bg-red-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="alert-triangle" class="w-3 h-3 text-red-600"></i>
                                    </div>
                                    <h5 class="text-sm font-medium text-red-800">Kernel Launch Failures</h5>
                                </div>
                                <ul class="mt-1 ml-6 list-disc text-xs text-red-700">
                                    <li>Incorrect grid or block dimensions</li>
                                    <li>Exceeding available shared memory</li>
                                    <li>Invalid kernel arguments</li>
                                </ul>
                                <div class="mt-2">
                                    <p class="text-xs text-red-700"><span class="font-medium">Solution:</span> Check launch parameters and use cudaGetLastError() after kernel launches.</p>
                                </div>
                            </div>
                            
                            <div class="bg-red-50 p-3 rounded-lg">
                                <div class="flex">
                                    <div class="p-1 bg-red-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="alert-triangle" class="w-3 h-3 text-red-600"></i>
                                    </div>
                                    <h5 class="text-sm font-medium text-red-800">Synchronization and Race Conditions</h5>
                                </div>
                                <ul class="mt-1 ml-6 list-disc text-xs text-red-700">
                                    <li>Improper use of __syncthreads()</li>
                                    <li>Global memory race conditions</li>
                                    <li>Forgetting to synchronize after asynchronous operations</li>
                                </ul>
                                <div class="mt-2">
                                    <p class="text-xs text-red-700"><span class="font-medium">Solution:</span> Carefully manage thread synchronization and use atomic operations when necessary.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <div>
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mb-6">
                            <h4 class="font-semibold mb-3">CUDA Debugging Techniques</h4>
                            <div class="space-y-3">
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="bug" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Error Checking</h5>
                                        <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mt-1 mb-1 overflow-x-auto">
                                            <pre><span class="text-green-400">// Check for errors after CUDA API calls</span>
cudaError_t err = cudaMalloc(&d_data, size);
<span class="text-blue-400">if</span> (err != cudaSuccess) {
    printf("CUDA Error: %s\n", 
           cudaGetErrorString(err));
}

<span class="text-green-400">// Or use a helper macro</span>
<span class="text-purple-400">#define</span> CUDA_CHECK(call) \
do { \
    cudaError_t err = call; \
    if (err != cudaSuccess) { \
        printf("CUDA error in %s:%d: %s\n", \
               __FILE__, __LINE__, \
               cudaGetErrorString(err)); \
        exit(EXIT_FAILURE); \
    } \
} while(0)</pre>
                                        </div>
                                    </div>
                                </div>
                                
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="bug" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Kernel Debugging with printf</h5>
                                        <p class="text-sm text-gray-600">CUDA supports printf statements inside kernels for basic debugging:</p>
                                        <div class="bg-gray-800 text-white p-2 rounded font-geist-mono text-xs mt-1 mb-1 overflow-x-auto">
                                            <pre><span class="text-blue-400">__global__</span> <span class="text-purple-400">void</span> <span class="text-blue-400">debugKernel</span>(<span class="text-purple-400">int</span>* data) {
    <span class="text-purple-400">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;
    <span class="text-blue-400">if</span> (idx < 10) {  <span class="text-green-400">// Limit output volume</span>
        printf("Thread %d, value: %d\n", idx, data[idx]);
    }
}</pre>
                                        </div>
                                    </div>
                                </div>
                                
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="bug" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Using Debugging Tools</h5>
                                        <ul class="mt-1 ml-4 list-disc text-sm text-gray-600">
                                            <li>CUDA-GDB for debugging CPU and GPU code</li>
                                            <li>NVIDIA Nsight for integrated debugging</li>
                                            <li>CUDA-MEMCHECK to detect memory errors</li>
                                            <li>Compute Sanitizer for functional correctness checking</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                        
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                            <h4 class="font-semibold mb-3">Debugging Strategies</h4>
                            <ul class="space-y-2 mb-4">
                                <li class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                        <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <span class="text-sm">Simplify your code: Start with the simplest version that works and incrementally add complexity</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                        <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <span class="text-sm">Validate on CPU: Implement a parallel algorithm on the CPU first and compare results</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                        <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <span class="text-sm">Reduce dimensions: Debug with smaller grid and block sizes initially</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                        <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <span class="text-sm">Error arrays: Use arrays to store error codes or intermediate values for debugging</span>
                                </li>
                            </ul>
                            <div class="p-3 bg-yellow-50 rounded-lg border border-yellow-100">
                                <div class="flex items-start">
                                    <div class="p-1 bg-yellow-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="lightbulb" class="w-3 h-3 text-yellow-700"></i>
                                    </div>
                                    <p class="text-xs text-yellow-700">When encountering CUDA errors, isolate the issue by commenting out parts of the code and gradually reintroducing them. Print intermediate values to track down where calculations begin to deviate from expected results.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="ai-applications" class="mb-20">
            <div class="border-l-4 border-primary pl-4 mb-6">
                <h2 class="text-3xl font-bold">5. CUDA for AI and Deep Learning</h2>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">AI Model Training</h3>
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 mb-6">
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-3">CUDA in Deep Learning</h4>
                        <p class="text-sm mb-4">CUDA is the foundation of modern deep learning, enabling the training of complex neural networks by providing massive parallel computing power. Most deep learning frameworks leverage NVIDIA GPUs through CUDA for accelerated training.</p>
                        
                        <div class="bg-gray-50 p-4 rounded-lg mb-4">
                            <h5 class="font-medium text-sm mb-2">Key Components</h5>
                            <ul class="space-y-2 text-sm">
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="library" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">cuDNN</span>
                                        <p class="text-xs text-gray-600">NVIDIA's library for deep neural networks that provides highly tuned implementations of routines like convolution, pooling, normalization, and activation layers.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="library" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">cuBLAS</span>
                                        <p class="text-xs text-gray-600">GPU-accelerated implementation of the Basic Linear Algebra Subprograms, optimized for matrix operations crucial for neural networks.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="library" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">NCCL</span>
                                        <p class="text-xs text-gray-600">NVIDIA Collective Communications Library for multi-GPU and multi-node collective communication primitives.</p>
                                    </div>
                                </li>
                            </ul>
                        </div>
                        
                        <div class="p-4 bg-purple-50 rounded-lg border border-purple-100">
                            <div class="flex items-start">
                                <div class="p-1 bg-purple-100 rounded-full mr-3 mt-1">
                                    <i data-lucide="code" class="w-4 h-4 text-purple-600"></i>
                                </div>
                                <div>
                                    <h5 class="font-medium text-sm mb-2 text-purple-800">Framework Integration</h5>
                                    <p class="text-xs text-purple-700">Most AI developers don't write CUDA code directly. Instead, frameworks like PyTorch and TensorFlow abstract the CUDA details while still leveraging its performance benefits.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <div>
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mb-6">
                            <h4 class="font-semibold mb-3">Performance Considerations</h4>
                            <ul class="space-y-3 text-sm">
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="zap" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Mixed Precision Training</span>
                                        <p class="text-xs text-gray-600">Using FP16 or bfloat16 with FP32 accumulation can significantly accelerate training while maintaining accuracy. Tensor Cores in modern NVIDIA GPUs are specifically designed to accelerate these operations.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="zap" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Data Loading Optimization</span>
                                        <p class="text-xs text-gray-600">GPU compute power often outpaces data loading. Using multiple CPU threads for data loading and preprocessing, along with pinned memory, can prevent the GPU from starving.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="zap" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Multi-GPU Training</span>
                                        <p class="text-xs text-gray-600">Distributing training across multiple GPUs can linearly scale performance. Data parallelism (splitting batches) or model parallelism (splitting model) are common approaches.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="zap" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Memory Management</span>
                                        <p class="text-xs text-gray-600">Careful batch size selection and techniques like gradient accumulation can help train large models on limited GPU memory.</p>
                                    </div>
                                </li>
                            </ul>
                        </div>
                        
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                            <h4 class="font-semibold mb-3">Example: PyTorch with CUDA</h4>
                            <div class="bg-gray-800 text-white p-3 rounded-lg font-geist-mono text-xs mb-4 overflow-x-auto">
                                <pre><span class="text-blue-400">import</span> torch

<span class="text-green-400"># Check if CUDA is available</span>
device = torch.device(<span class="text-yellow-400">"cuda"</span> if torch.cuda.is_available() 
                     else <span class="text-yellow-400">"cpu"</span>)
print(<span class="text-yellow-400">f"Using {device} device"</span>)

<span class="text-green-400"># Create tensors on GPU</span>
x = torch.rand(5, 3).to(device)
y = torch.rand(5, 3).to(device)

<span class="text-green-400"># Operations run on GPU</span>
z = x + y

<span class="text-green-400"># Define a simple neural network</span>
<span class="text-blue-400">class</span> <span class="text-purple-400">SimpleNN</span>(torch.nn.Module):
    <span class="text-blue-400">def</span> <span class="text-green-400">__init__</span>(self):
        super(SimpleNN, self).__init__()
        self.fc1 = torch.nn.Linear(3, 64)
        self.fc2 = torch.nn.Linear(64, 1)
        
    <span class="text-blue-400">def</span> <span class="text-green-400">forward</span>(self, x):
        x = torch.nn.functional.relu(self.fc1(x))
        x = self.fc2(x)
        <span class="text-blue-400">return</span> x

<span class="text-green-400"># Create model and move to GPU</span>
model = SimpleNN().to(device)

<span class="text-green-400"># Training loop would use GPU acceleration</span>
<span class="text-green-400"># ...</span></pre>
                            </div>
                            <div class="p-3 bg-blue-50 rounded-lg border border-blue-100">
                                <div class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="info" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <p class="text-xs text-blue-700">PyTorch and TensorFlow automatically leverage CUDA when available, using optimized kernels for operations like matrix multiplication, convolution, and various activation functions.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">AI Model Inference</h3>
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 mb-6">
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-3">Optimizing Inference with CUDA</h4>
                        <p class="text-sm mb-4">AI inference is the process of using a trained model to generate predictions from input data. CUDA accelerates inference by executing model computations in parallel, significantly reducing latency and increasing throughput.</p>
                        
                        <div class="bg-gray-50 p-4 rounded-lg mb-4">
                            <h5 class="font-medium text-sm mb-2">NVIDIA Inference Solutions</h5>
                            <ul class="space-y-2 text-sm">
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="zap" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">TensorRT</span>
                                        <p class="text-xs text-gray-600">High-performance inference optimizer and runtime that delivers low latency and high throughput for deep learning applications.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="zap" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Triton Inference Server</span>
                                        <p class="text-xs text-gray-600">Inference serving software that standardizes model deployment and execution across diverse computing platforms.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-2 mt-0">
                                        <i data-lucide="zap" class="w-3 h-3 text-primary"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">NVIDIA NIM</span>
                                        <p class="text-xs text-gray-600">Microservices for deploying high-performance AI inferencing across various environments.</p>
                                    </div>
                                </li>
                            </ul>
                        </div>
                        
                        <div class="bg-gray-50 p-4 rounded-lg">
                            <h5 class="font-medium text-sm mb-2">Inference Optimization Techniques</h5>
                            <ul class="space-y-2 text-sm">
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span>Quantization (INT8, FP16, BF16)</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span>Layer fusion and kernel optimization</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span>Dynamic tensor memory management</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span>Multi-stream execution</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span>Batch processing for higher throughput</span>
                                </li>
                            </ul>
                        </div>
                    </div>
                    
                    <div>
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mb-6">
                            <h4 class="font-semibold mb-3">TensorRT Example</h4>
                            <div class="bg-gray-800 text-white p-3 rounded-lg font-geist-mono text-xs mb-3 overflow-x-auto">
                                <pre><span class="text-blue-400">import</span> tensorrt <span class="text-blue-400">as</span> trt
<span class="text-blue-400">import</span> pycuda.driver <span class="text-blue-400">as</span> cuda

<span class="text-green-400"># Logger for TensorRT</span>
logger = trt.Logger(trt.Logger.WARNING)

<span class="text-green-400"># Create builder</span>
builder = trt.Builder(logger)
network = builder.create_network(
    1 << <span class="text-purple-400">int</span>(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)
)
config = builder.create_builder_config()

<span class="text-green-400"># Set precision (FP16 for faster inference)</span>
config.set_flag(trt.BuilderFlag.FP16)

<span class="text-green-400"># Set max workspace size</span>
config.max_workspace_size = 1 << 30  <span class="text-green-400"># 1GB</span>

<span class="text-green-400"># Parse ONNX model</span>
parser = trt.OnnxParser(network, logger)
with open(<span class="text-yellow-400">'model.onnx'</span>, <span class="text-yellow-400">'rb'</span>) <span class="text-blue-400">as</span> model:
    parser.parse(model.read())

<span class="text-green-400"># Build optimized engine</span>
engine = builder.build_engine(network, config)

<span class="text-green-400"># Deserialize for inference</span>
runtime = trt.Runtime(logger)
with open(<span class="text-yellow-400">'model.trt'</span>, <span class="text-yellow-400">'wb'</span>) <span class="text-blue-400">as</span> f:
    f.write(engine.serialize())

<span class="text-green-400"># Allocate buffers for inference</span>
<span class="text-green-400"># Create CUDA context, etc.</span>
<span class="text-green-400"># Run inference</span></pre>
                            </div>
                            <p class="text-xs text-gray-600 mb-3">This example shows how TensorRT can be used to optimize an ONNX model for inference. The optimized model is typically 2-5 faster than the original framework implementation.</p>
                            <div class="p-3 bg-yellow-50 rounded-lg border border-yellow-100">
                                <div class="flex items-start">
                                    <div class="p-1 bg-yellow-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="lightbulb" class="w-3 h-3 text-yellow-700"></i>
                                    </div>
                                    <p class="text-xs text-yellow-700">TensorRT performs various optimizations including layer fusion, precision calibration, kernel auto-tuning, and dynamic tensor memory to maximize inference performance on NVIDIA GPUs.</p>
                                </div>
                            </div>
                        </div>
                        
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                            <h4 class="font-semibold mb-3">Performance Comparison</h4>
                            <div class="w-full h-60 bg-gray-50 rounded-lg flex items-center justify-center p-4">
                                <div class="w-full max-w-md">
                                    <h5 class="text-sm font-medium text-center mb-3">Relative Inference Performance</h5>
                                    <div class="space-y-4 w-full">
                                        <div>
                                            <div class="flex items-center">
                                                <span class="text-xs w-48 font-medium">CPU (Baseline)</span>
                                                <div class="flex-grow h-6 bg-gray-200 rounded-full overflow-hidden">
                                                    <div class="h-full bg-blue-500 rounded-full" style="width: 20%"></div>
                                                </div>
                                                <span class="text-xs ml-2 w-10">1</span>
                                            </div>
                                        </div>
                                        <div>
                                            <div class="flex items-center">
                                                <span class="text-xs w-48 font-medium">Raw GPU (Framework)</span>
                                                <div class="flex-grow h-6 bg-gray-200 rounded-full overflow-hidden">
                                                    <div class="h-full bg-blue-600 rounded-full" style="width: 60%"></div>
                                                </div>
                                                <span class="text-xs ml-2 w-10">3</span>
                                            </div>
                                        </div>
                                        <div>
                                            <div class="flex items-center">
                                                <span class="text-xs w-48 font-medium">TensorRT FP32</span>
                                                <div class="flex-grow h-6 bg-gray-200 rounded-full overflow-hidden">
                                                    <div class="h-full bg-indigo-500 rounded-full" style="width: 100%"></div>
                                                </div>
                                                <span class="text-xs ml-2 w-10">5</span>
                                            </div>
                                        </div>
                                        <div>
                                            <div class="flex items-center">
                                                <span class="text-xs w-48 font-medium">TensorRT FP16</span>
                                                <div class="flex-grow h-6 bg-gray-200 rounded-full overflow-hidden">
                                                    <div class="h-full bg-purple-500 rounded-full" style="width: 180%"></div>
                                                </div>
                                                <span class="text-xs ml-2 w-10">9</span>
                                            </div>
                                        </div>
                                        <div>
                                            <div class="flex items-center">
                                                <span class="text-xs w-48 font-medium">TensorRT INT8</span>
                                                <div class="flex-grow h-6 bg-gray-200 rounded-full overflow-hidden">
                                                    <div class="h-full bg-primary rounded-full" style="width: 300%"></div>
                                                </div>
                                                <span class="text-xs ml-2 w-10">15</span>
                                            </div>
                                        </div>
                                    </div>
                                    <p class="text-xs text-gray-500 text-center mt-2">*Representative performance for a typical CNN model. Actual speedups vary by model architecture.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Large Language Models (LLMs)</h3>
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 mb-6">
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-3">CUDA for LLM Training</h4>
                        <p class="text-sm mb-4">Large Language Models (LLMs) like GPT, LLaMA, and BERT have become central to modern AI. Training these massive models is one of the most computationally intensive tasks, requiring extensive CUDA optimization.</p>
                        
                        <div class="bg-gray-50 p-4 rounded-lg mb-4">
                            <h5 class="font-medium text-sm mb-2">Key Challenges</h5>
                            <ul class="space-y-2 text-sm">
                                <li class="flex items-start">
                                    <div class="p-1 bg-red-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="alert-circle" class="w-3 h-3 text-red-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Memory Constraints</span>
                                        <p class="text-xs text-gray-600">Modern LLMs often have billions of parameters that won't fit on a single GPU.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-red-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="alert-circle" class="w-3 h-3 text-red-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Computational Demands</span>
                                        <p class="text-xs text-gray-600">Self-attention mechanisms scale quadratically with sequence length, creating computational bottlenecks.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-red-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="alert-circle" class="w-3 h-3 text-red-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Training Stability</span>
                                        <p class="text-xs text-gray-600">Distributed training introduces challenges with numerical stability, especially with mixed precision.</p>
                                    </div>
                                </li>
                            </ul>
                        </div>
                        
                        <div class="bg-gray-50 p-4 rounded-lg">
                            <h5 class="font-medium text-sm mb-2">CUDA-Optimized Solutions</h5>
                            <ul class="space-y-2 text-sm">
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Model Parallelism</span>
                                        <p class="text-xs text-gray-600">Splitting the model across multiple GPUs, with CUDA handling the inter-GPU communication.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Tensor Parallelism</span>
                                        <p class="text-xs text-gray-600">Splitting individual layers across GPUs for parallel computation.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Optimized Attention</span>
                                        <p class="text-xs text-gray-600">CUDA kernels like FlashAttention that optimize memory access patterns for transformer attention calculations.</p>
                                    </div>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="check" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <div>
                                        <span class="font-medium">Memory Offloading</span>
                                        <p class="text-xs text-gray-600">ZeRO (Zero Redundancy Optimizer) techniques that offload optimizer states, gradients, or even parameters to CPU memory and load them back as needed.</p>
                                    </div>
                                </li>
                            </ul>
                        </div>
                    </div>
                    
                    <div>
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                            <h4 class="font-semibold mb-3">LLM Inference Optimization</h4>
                            <p class="text-sm mb-4">Inference for LLMs presents unique challenges compared to traditional neural networks due to the autoregressive generation process and massive model sizes.</p>
                            
                            <div class="space-y-4">
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="cpu" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Key CUDA Optimizations</h5>
                                        <ul class="space-y-1 ml-1 text-xs text-gray-600">
                                            <li> <span class="font-medium">KV Caching:</span> Caching key and value tensors to avoid redundant computation during generation</li>
                                            <li> <span class="font-medium">Quantization:</span> INT8 and INT4 quantization to reduce memory footprint and improve throughput</li>
                                            <li> <span class="font-medium">Continuous Batching:</span> Dynamic scheduling of requests to maximize GPU utilization</li>
                                            <li> <span class="font-medium">Kernel Fusion:</span> Combining multiple small operations into single CUDA kernels</li>
                                            <li> <span class="font-medium">Speculative Decoding:</span> Using a smaller model to predict tokens that are verified by the larger model</li>
                                        </ul>
                                    </div>
                                </div>
                                
                                <div class="flex items-start">
                                    <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                        <i data-lucide="layers" class="w-4 h-4 text-primary"></i>
                                    </div>
                                    <div>
                                        <h5 class="text-sm font-medium mb-1">Popular CUDA-Accelerated Frameworks</h5>
                                        <ul class="space-y-1 ml-1 text-xs text-gray-600">
                                            <li> <span class="font-medium">FasterTransformer:</span> NVIDIA's optimized transformer implementation</li>
                                            <li> <span class="font-medium">vLLM:</span> High-throughput and memory-efficient LLM serving with PagedAttention</li>
                                            <li> <span class="font-medium">TensorRT-LLM:</span> Optimized kernels for large language models</li>
                                            <li> <span class="font-medium">FlashAttention:</span> Memory-efficient attention mechanism with better asymptotic complexity</li>
                                            <li> <span class="font-medium">DeepSpeed-Inference:</span> Optimized inference with ZeRO-Inference for large models</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                            
                            <div class="mt-4 p-3 bg-blue-50 rounded-lg border border-blue-100">
                                <div class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="info" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <p class="text-xs text-blue-700">Advanced CUDA optimization can reduce the latency of LLM token generation by 2-10, enabling real-time conversation with models that would otherwise be too slow for interactive use.</p>
                                </div>
                            </div>
                        </div>
                        
                        <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mt-6">
                            <h4 class="font-semibold mb-3">Emerging LLM Techniques</h4>
                            <div class="space-y-4">
                                <div class="flex items-start">
                                    <div class="p-1 bg-purple-100 rounded-full mr-3 mt-0">
                                        <i data-lucide="sparkles" class="w-4 h-4 text-purple-600"></i>
                                    </div>
                                    <div>
                                        <span class="text-sm font-medium">CUDA-Free Inference</span>
                                        <p class="text-xs text-gray-600">Using OpenAI's Triton language to enable LLMs to run on various GPUs, including AMD and Intel. This approach can achieve 60-80% of CUDA performance while expanding hardware compatibility.</p>
                                    </div>
                                </div>
                                
                                <div class="flex items-start">
                                    <div class="p-1 bg-purple-100 rounded-full mr-3 mt-0">
                                        <i data-lucide="sparkles" class="w-4 h-4 text-purple-600"></i>
                                    </div>
                                    <div>
                                        <span class="text-sm font-medium">CUDA DTX (Distributed Execution)</span>
                                        <p class="text-xs text-gray-600">NVIDIA's next-generation CUDA aims to scale from individual GPUs to entire data centers with unified machine models and resilient execution for large-scale LLM training.</p>
                                    </div>
                                </div>
                                
                                <div class="flex items-start">
                                    <div class="p-1 bg-purple-100 rounded-full mr-3 mt-0">
                                        <i data-lucide="sparkles" class="w-4 h-4 text-purple-600"></i>
                                    </div>
                                    <div>
                                        <span class="text-sm font-medium">Mixture-of-Experts (MoE)</span>
                                        <p class="text-xs text-gray-600">Specialized CUDA kernels for efficiently handling the sparse activation patterns in MoE models, enabling even larger effective model sizes without proportional computational cost.</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Future Developments</h3>
                <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <div class="flex items-center mb-4">
                            <div class="p-2 bg-indigo-50 rounded-full mr-3">
                                <i data-lucide="cpu" class="w-6 h-6 text-indigo-600"></i>
                            </div>
                            <h4 class="font-semibold">AI-Specific Hardware</h4>
                        </div>
                        <p class="text-sm text-gray-600 mb-4">Future NVIDIA GPUs will feature more specialized AI components like Tensor Cores and additional acceleration for specific operations. CUDA will continue to evolve to support these new hardware capabilities.</p>
                        <div class="space-y-2">
                            <div class="flex items-center">
                                <div class="p-1 bg-indigo-100 rounded-full mr-2">
                                    <i data-lucide="check" class="w-3 h-3 text-indigo-600"></i>
                                </div>
                                <span class="text-xs">Enhanced Tensor Cores</span>
                            </div>
                            <div class="flex items-center">
                                <div class="p-1 bg-indigo-100 rounded-full mr-2">
                                    <i data-lucide="check" class="w-3 h-3 text-indigo-600"></i>
                                </div>
                                <span class="text-xs">Transformer Engine optimizations</span>
                            </div>
                            <div class="flex items-center">
                                <div class="p-1 bg-indigo-100 rounded-full mr-2">
                                    <i data-lucide="check" class="w-3 h-3 text-indigo-600"></i>
                                </div>
                                <span class="text-xs">Chiplet designs for specialized workloads</span>
                            </div>
                        </div>
                    </div>
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <div class="flex items-center mb-4">
                            <div class="p-2 bg-blue-50 rounded-full mr-3">
                                <i data-lucide="network" class="w-6 h-6 text-blue-600"></i>
                            </div>
                            <h4 class="font-semibold">Heterogeneous Computing</h4>
                        </div>
                        <p class="text-sm text-gray-600 mb-4">Future CUDA will enhance support for heterogeneous architectures, combining GPUs with other processing units like CPUs and specialized accelerators for more flexible computing.</p>
                        <div class="space-y-2">
                            <div class="flex items-center">
                                <div class="p-1 bg-blue-100 rounded-full mr-2">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <span class="text-xs">Unified memory architecture</span>
                            </div>
                            <div class="flex items-center">
                                <div class="p-1 bg-blue-100 rounded-full mr-2">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <span class="text-xs">Cross-device task scheduling</span>
                            </div>
                            <div class="flex items-center">
                                <div class="p-1 bg-blue-100 rounded-full mr-2">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <span class="text-xs">Optimized multi-node processing</span>
                            </div>
                        </div>
                    </div>
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <div class="flex items-center mb-4">
                            <div class="p-2 bg-purple-50 rounded-full mr-3">
                                <i data-lucide="sparkles" class="w-6 h-6 text-purple-600"></i>
                            </div>
                            <h4 class="font-semibold">CUDA DTX</h4>
                        </div>
                        <p class="text-sm text-gray-600 mb-4">CUDA Distributed Execution (DTX) is NVIDIA's next-generation platform aimed at scaling from individual GPUs to entire data centers with unified programming models.</p>
                        <div class="space-y-2">
                            <div class="flex items-center">
                                <div class="p-1 bg-purple-100 rounded-full mr-2">
                                    <i data-lucide="check" class="w-3 h-3 text-purple-600"></i>
                                </div>
                                <span class="text-xs">Data center-scale programming</span>
                            </div>
                            <div class="flex items-center">
                                <div class="p-1 bg-purple-100 rounded-full mr-2">
                                    <i data-lucide="check" class="w-3 h-3 text-purple-600"></i>
                                </div>
                                <span class="text-xs">Unified machine model</span>
                            </div>
                            <div class="flex items-center">
                                <div class="p-1 bg-purple-100 rounded-full mr-2">
                                    <i data-lucide="check" class="w-3 h-3 text-purple-600"></i>
                                </div>
                                <span class="text-xs">Resilient distributed execution</span>
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mt-6">
                    <h4 class="font-semibold mb-4">Market Growth</h4>
                    <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                        <div class="h-64 bg-gray-50 rounded-lg flex items-center justify-center p-4">
                            <div class="w-full">
                                <h5 class="text-sm font-medium text-center mb-3">GPU as a Service (GPUaaS) Market Projection</h5>
                                <div class="relative h-44">
                                    <div class="absolute bottom-0 left-0 w-full h-full flex items-end">
                                        <div class="w-1/6 h-12 bg-blue-200 relative group">
                                            <div class="absolute -top-8 left-1/2 transform -translate-x-1/2 invisible group-hover:visible bg-blue-600 text-white text-xs py-1 px-2 rounded">
                                                $3.5 billion
                                            </div>
                                            <div class="absolute bottom-0 left-0 w-full text-center text-xs">
                                                2024
                                            </div>
                                        </div>
                                        <div class="w-1/6 h-24 bg-blue-300 relative group">
                                            <div class="absolute -top-8 left-1/2 transform -translate-x-1/2 invisible group-hover:visible bg-blue-600 text-white text-xs py-1 px-2 rounded">
                                                $7.0 billion
                                            </div>
                                            <div class="absolute bottom-0 left-0 w-full text-center text-xs">
                                                2026
                                            </div>
                                        </div>
                                        <div class="w-1/6 h-36 bg-blue-400 relative group">
                                            <div class="absolute -top-8 left-1/2 transform -translate-x-1/2 invisible group-hover:visible bg-blue-600 text-white text-xs py-1 px-2 rounded">
                                                $12.9 billion
                                            </div>
                                            <div class="absolute bottom-0 left-0 w-full text-center text-xs">
                                                2028
                                            </div>
                                        </div>
                                        <div class="w-1/6 h-40 bg-blue-500 relative group">
                                            <div class="absolute -top-8 left-1/2 transform -translate-x-1/2 invisible group-hover:visible bg-blue-600 text-white text-xs py-1 px-2 rounded">
                                                $20.5 billion
                                            </div>
                                            <div class="absolute bottom-0 left-0 w-full text-center text-xs">
                                                2030
                                            </div>
                                        </div>
                                        <div class="w-1/6 h-44 bg-blue-600 relative group">
                                            <div class="absolute -top-8 left-1/2 transform -translate-x-1/2 invisible group-hover:visible bg-blue-600 text-white text-xs py-1 px-2 rounded">
                                                $41.1 billion
                                            </div>
                                            <div class="absolute bottom-0 left-0 w-full text-center text-xs">
                                                2032
                                            </div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div>
                            <div class="mb-4">
                                <h5 class="text-sm font-medium mb-2">CUDA-Accelerated Domains</h5>
                                <p class="text-sm text-gray-600">GPU and CUDA adoption is expanding beyond traditional AI applications into new domains:</p>
                            </div>
                            <div class="grid grid-cols-2 gap-4">
                                <div class="p-3 bg-gray-50 rounded-lg">
                                    <div class="flex items-center mb-2">
                                        <div class="p-1 bg-green-100 rounded-full mr-2">
                                            <i data-lucide="microscope" class="w-3 h-3 text-green-600"></i>
                                        </div>
                                        <h6 class="text-xs font-medium">Computational Biology</h6>
                                    </div>
                                    <p class="text-xs text-gray-600">Genomics, protein folding, molecular dynamics simulations</p>
                                </div>
                                <div class="p-3 bg-gray-50 rounded-lg">
                                    <div class="flex items-center mb-2">
                                        <div class="p-1 bg-red-100 rounded-full mr-2">
                                            <i data-lucide="atom" class="w-3 h-3 text-red-600"></i>
                                        </div>
                                        <h6 class="text-xs font-medium">Quantum Computing</h6>
                                    </div>
                                    <p class="text-xs text-gray-600">Quantum circuit simulators, hybrid quantum-classical algorithms</p>
                                </div>
                                <div class="p-3 bg-gray-50 rounded-lg">
                                    <div class="flex items-center mb-2">
                                        <div class="p-1 bg-indigo-100 rounded-full mr-2">
                                            <i data-lucide="radio" class="w-3 h-3 text-indigo-600"></i>
                                        </div>
                                        <h6 class="text-xs font-medium">6G Research</h6>
                                    </div>
                                    <p class="text-xs text-gray-600">Signal processing, massive MIMO, AI-enabled communications</p>
                                </div>
                                <div class="p-3 bg-gray-50 rounded-lg">
                                    <div class="flex items-center mb-2">
                                        <div class="p-1 bg-amber-100 rounded-full mr-2">
                                            <i data-lucide="globe" class="w-3 h-3 text-amber-600"></i>
                                        </div>
                                        <h6 class="text-xs font-medium">Climate Science</h6>
                                    </div>
                                    <p class="text-xs text-gray-600">Climate modeling, weather prediction, natural disaster forecasting</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="resources" class="mb-20">
            <div class="border-l-4 border-primary pl-4 mb-6">
                <h2 class="text-3xl font-bold">6. Learning Resources</h2>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Books and Documentation</h3>
                <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-6">
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <div class="flex items-start mb-4">
                            <div class="p-2 bg-primary/10 rounded-lg mr-3 mt-1">
                                <i data-lucide="book" class="w-5 h-5 text-primary"></i>
                            </div>
                            <div>
                                <h4 class="font-semibold mb-1">Essential CUDA Books</h4>
                                <p class="text-xs text-gray-500">Comprehensive resources for in-depth learning</p>
                            </div>
                        </div>
                        <ul class="space-y-3">
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">Programming Massively Parallel Processors</span>
                                    <p class="text-xs text-gray-600">By Wen-mei W. Hwu - Explains how to map problems onto GPU programming model</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">CUDA by Example</span>
                                    <p class="text-xs text-gray-600">By Jason Sanders and Edward Kandrot - Ideal for self-taught beginners</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">Professional CUDA C Programming</span>
                                    <p class="text-xs text-gray-600">Comprehensive guide from beginner to advanced topics</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">The CUDA Handbook</span>
                                    <p class="text-xs text-gray-600">By Nicholas Wilt - Low-level details and optimization techniques</p>
                                </div>
                            </li>
                        </ul>
                    </div>
                    
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <div class="flex items-start mb-4">
                            <div class="p-2 bg-primary/10 rounded-lg mr-3 mt-1">
                                <i data-lucide="file-text" class="w-5 h-5 text-primary"></i>
                            </div>
                            <div>
                                <h4 class="font-semibold mb-1">Official Documentation</h4>
                                <p class="text-xs text-gray-500">Essential reference materials from NVIDIA</p>
                            </div>
                        </div>
                        <ul class="space-y-3">
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">CUDA C++ Programming Guide</span>
                                    <p class="text-xs text-gray-600">Comprehensive guide to the CUDA programming model and interface</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">CUDA C++ Best Practices Guide</span>
                                    <p class="text-xs text-gray-600">Optimization strategies and recommendations</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">CUDA Runtime API Reference</span>
                                    <p class="text-xs text-gray-600">Detailed documentation of all CUDA runtime functions</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">CUDA Toolkit Documentation</span>
                                    <p class="text-xs text-gray-600">Information on libraries, tools, and features included in CUDA Toolkit</p>
                                </div>
                            </li>
                        </ul>
                    </div>
                    
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <div class="flex items-start mb-4">
                            <div class="p-2 bg-primary/10 rounded-lg mr-3 mt-1">
                                <i data-lucide="brain" class="w-5 h-5 text-primary"></i>
                            </div>
                            <div>
                                <h4 class="font-semibold mb-1">AI-Specific Resources</h4>
                                <p class="text-xs text-gray-500">Materials focused on AI applications</p>
                            </div>
                        </div>
                        <ul class="space-y-3">
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">cuDNN Documentation</span>
                                    <p class="text-xs text-gray-600">NVIDIA CUDA Deep Neural Network library reference</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">TensorRT Documentation</span>
                                    <p class="text-xs text-gray-600">High-performance deep learning inference optimizer and runtime</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">Deep Learning SDK Documentation</span>
                                    <p class="text-xs text-gray-600">Resources for GPU-accelerated deep learning</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">CUDA Python Libraries</span>
                                    <p class="text-xs text-gray-600">References for NumPy-like libraries that leverage GPU acceleration</p>
                                </div>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Online Courses and Tutorials</h3>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8 mb-6">
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-4">NVIDIA Deep Learning Institute</h4>
                        <p class="text-sm mb-4">NVIDIA's Deep Learning Institute (DLI) offers hands-on training in AI, accelerated computing, and accelerated data science.</p>
                        
                        <div class="space-y-4">
                            <div class="flex items-start">
                                <div class="p-1 bg-green-100 rounded-full mr-3 mt-1">
                                    <i data-lucide="graduation-cap" class="w-4 h-4 text-green-600"></i>
                                </div>
                                <div>
                                    <h5 class="text-sm font-medium mb-1">Self-Paced Courses</h5>
                                    <ul class="ml-1 space-y-1">
                                        <li class="text-xs text-gray-600"> Getting Started with Accelerated Computing with CUDA C/C++</li>
                                        <li class="text-xs text-gray-600"> Fundamentals of Accelerated Computing with CUDA Python</li>
                                        <li class="text-xs text-gray-600"> Scaling Workloads Across Multiple GPUs with CUDA C++</li>
                                    </ul>
                                </div>
                            </div>
                            
                            <div class="flex items-start">
                                <div class="p-1 bg-green-100 rounded-full mr-3 mt-1">
                                    <i data-lucide="users" class="w-4 h-4 text-green-600"></i>
                                </div>
                                <div>
                                    <h5 class="text-sm font-medium mb-1">Workshop Training</h5>
                                    <ul class="ml-1 space-y-1">
                                        <li class="text-xs text-gray-600"> Instructor-led sessions available worldwide</li>
                                        <li class="text-xs text-gray-600"> Taught by industry experts</li>
                                        <li class="text-xs text-gray-600"> Focused on real-world problem solving</li>
                                    </ul>
                                </div>
                            </div>
                            
                            <div class="flex items-start">
                                <div class="p-1 bg-green-100 rounded-full mr-3 mt-1">
                                    <i data-lucide="award" class="w-4 h-4 text-green-600"></i>
                                </div>
                                <div>
                                    <h5 class="text-sm font-medium mb-1">Certification</h5>
                                    <p class="text-xs text-gray-600">Earn certificates to demonstrate competency and support career growth</p>
                                </div>
                            </div>
                        </div>
                        
                        <div class="mt-4 p-3 bg-blue-50 rounded-lg">
                            <p class="text-xs text-blue-700">Visit <a href="https://www.nvidia.com/en-us/training/" target="_blank" class="text-blue-600 underline">NVIDIA DLI website</a> to explore available courses and workshops.</p>
                        </div>
                    </div>
                    
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <h4 class="font-semibold mb-4">Free Online Resources</h4>
                        <div class="space-y-4">
                            <div class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-3 mt-1">
                                    <i data-lucide="video" class="w-4 h-4 text-blue-600"></i>
                                </div>
                                <div>
                                    <h5 class="text-sm font-medium mb-1">Video Tutorials</h5>
                                    <ul class="ml-1 space-y-1">
                                        <li class="text-xs text-gray-600"> NVIDIA Developer YouTube Channel</li>
                                        <li class="text-xs text-gray-600"> GTC Session Recordings</li>
                                        <li class="text-xs text-gray-600"> "An Even Easier Introduction to CUDA" webinar</li>
                                    </ul>
                                </div>
                            </div>
                            
                            <div class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-3 mt-1">
                                    <i data-lucide="code" class="w-4 h-4 text-blue-600"></i>
                                </div>
                                <div>
                                    <h5 class="text-sm font-medium mb-1">Tutorials and Code Samples</h5>
                                    <ul class="ml-1 space-y-1">
                                        <li class="text-xs text-gray-600"> NVIDIA CUDA Code Samples Repository</li>
                                        <li class="text-xs text-gray-600"> NVIDIA Developer Blog tutorials</li>
                                        <li class="text-xs text-gray-600"> GitHub repositories with example code</li>
                                        <li class="text-xs text-gray-600"> PyTorch CUDA Extension tutorials</li>
                                    </ul>
                                </div>
                            </div>
                            
                            <div class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-3 mt-1">
                                    <i data-lucide="school" class="w-4 h-4 text-blue-600"></i>
                                </div>
                                <div>
                                    <h5 class="text-sm font-medium mb-1">University Courses</h5>
                                    <ul class="ml-1 space-y-1">
                                        <li class="text-xs text-gray-600"> Udacity "CS344 Intro To Parallel Programming"</li>
                                        <li class="text-xs text-gray-600"> Stanford University CUDA course materials</li>
                                        <li class="text-xs text-gray-600"> University of Illinois CUDA programming course</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                        <div class="mt-4 p-3 bg-yellow-50 rounded-lg">
                            <div class="flex items-start">
                                <div class="p-1 bg-yellow-100 rounded-full mr-2 mt-0">
                                    <i data-lucide="lightbulb" class="w-3 h-3 text-yellow-700"></i>
                                </div>
                                <p class="text-xs text-yellow-700">Learning by doing is especially effective with CUDA. Start with simple examples and gradually work your way up to more complex applications.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Community and Support</h3>
                <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <div class="flex items-center mb-4">
                            <div class="p-2 bg-green-50 rounded-full mr-3">
                                <i data-lucide="message-circle" class="w-5 h-5 text-green-600"></i>
                            </div>
                            <h4 class="font-semibold">Forums & Discussion</h4>
                        </div>
                        <ul class="space-y-3">
                            <li class="flex items-start">
                                <div class="p-1 bg-green-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-green-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">NVIDIA Developer Forums</span>
                                    <p class="text-xs text-gray-600">Official support from NVIDIA engineers and community members</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-green-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-green-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">Stack Overflow</span>
                                    <p class="text-xs text-gray-600">Tag: [cuda], [gpu], [gpu-programming]</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-green-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-green-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">Reddit</span>
                                    <p class="text-xs text-gray-600">r/CUDA, r/gpgpu, r/MachineLearning</p>
                                </div>
                            </li>
                        </ul>
                    </div>
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <div class="flex items-center mb-4">
                            <div class="p-2 bg-blue-50 rounded-full mr-3">
                                <i data-lucide="github" class="w-5 h-5 text-blue-600"></i>
                            </div>
                            <h4 class="font-semibold">Open Source Projects</h4>
                        </div>
                        <ul class="space-y-3">
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">NVIDIA CUDA Samples</span>
                                    <p class="text-xs text-gray-600">Official examples demonstrating CUDA features</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">RAPIDS</span>
                                    <p class="text-xs text-gray-600">GPU-accelerated data science libraries (cuDF, cuML)</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-blue-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-blue-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">Trending CUDA Projects</span>
                                    <p class="text-xs text-gray-600">FlashInfer, instant-ngp, CuGraph</p>
                                </div>
                            </li>
                        </ul>
                    </div>
                    <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                        <div class="flex items-center mb-4">
                            <div class="p-2 bg-purple-50 rounded-full mr-3">
                                <i data-lucide="calendar" class="w-5 h-5 text-purple-600"></i>
                            </div>
                            <h4 class="font-semibold">Conferences & Events</h4>
                        </div>
                        <ul class="space-y-3">
                            <li class="flex items-start">
                                <div class="p-1 bg-purple-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-purple-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">GTC (GPU Technology Conference)</span>
                                    <p class="text-xs text-gray-600">NVIDIA's premier conference with CUDA sessions</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-purple-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-purple-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">SuperComputing (SC)</span>
                                    <p class="text-xs text-gray-600">International conference for high-performance computing</p>
                                </div>
                            </li>
                            <li class="flex items-start">
                                <div class="p-1 bg-purple-100 rounded-full mr-2 mt-1">
                                    <i data-lucide="check" class="w-3 h-3 text-purple-600"></i>
                                </div>
                                <div>
                                    <span class="text-sm font-medium">Domain-Specific Conferences</span>
                                    <p class="text-xs text-gray-600">CVPR, NeurIPS, ICML (for AI applications)</p>
                                </div>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="mb-10">
                <h3 class="text-xl font-semibold mb-4">Learning Paths</h3>
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mb-6">
                    <div class="grid grid-cols-1 md:grid-cols-3 gap-8">
                        <div>
                            <div class="rounded-full w-16 h-16 flex items-center justify-center bg-green-100 text-green-600 text-2xl font-bold mb-4">
                                1
                            </div>
                            <h4 class="font-semibold mb-3">Beginner Path</h4>
                            <ul class="space-y-2">
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span class="text-sm">Learn C/C++ fundamentals</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span class="text-sm">Complete "An Even Easier Introduction to CUDA" course</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span class="text-sm">Experiment with CUDA sample code</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span class="text-sm">Read "CUDA by Example" book</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-green-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-green-600"></i>
                                    </div>
                                    <span class="text-sm">Implement basic vector operations in CUDA</span>
                                </li>
                            </ul>
                        </div>
                        <div>
                            <div class="rounded-full w-16 h-16 flex items-center justify-center bg-blue-100 text-blue-600 text-2xl font-bold mb-4">
                                2
                            </div>
                            <h4 class="font-semibold mb-3">Intermediate Path</h4>
                            <ul class="space-y-2">
                                <li class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <span class="text-sm">Study CUDA programming model in depth</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <span class="text-sm">Learn memory optimization techniques</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <span class="text-sm">Implement shared memory algorithms</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <span class="text-sm">Read "Professional CUDA C Programming"</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-blue-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-blue-600"></i>
                                    </div>
                                    <span class="text-sm">Complete Scaling Workloads Across Multiple GPUs with CUDA C++ course</span>
                                </li>
                            </ul>
                        </div>
                        <div>
                            <div class="rounded-full w-16 h-16 flex items-center justify-center bg-purple-100 text-purple-600 text-2xl font-bold mb-4">
                                3
                            </div>
                            <h4 class="font-semibold mb-3">Advanced Path</h4>
                            <ul class="space-y-2">
                                <li class="flex items-start">
                                    <div class="p-1 bg-purple-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-purple-600"></i>
                                    </div>
                                    <span class="text-sm">Master advanced optimization techniques</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-purple-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-purple-600"></i>
                                    </div>
                                    <span class="text-sm">Learn to use profiling tools (Nsight Systems, Nsight Compute)</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-purple-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-purple-600"></i>
                                    </div>
                                    <span class="text-sm">Study CUDA libraries implementation (cuBLAS, cuDNN)</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-purple-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-purple-600"></i>
                                    </div>
                                    <span class="text-sm">Explore multi-GPU programming</span>
                                </li>
                                <li class="flex items-start">
                                    <div class="p-1 bg-purple-100 rounded-full mr-2 mt-0">
                                        <i data-lucide="arrow-right" class="w-3 h-3 text-purple-600"></i>
                                    </div>
                                    <span class="text-sm">Contribute to open-source CUDA projects</span>
                                </li>
                            </ul>
                        </div>
                    </div>
                </div>
                
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm mb-6">
                    <h4 class="font-semibold mb-4">Specialization Paths</h4>
                    <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                        <div class="p-4 bg-gray-50 rounded-lg">
                            <div class="flex items-center mb-3">
                                <div class="p-1 bg-indigo-100 rounded-full mr-2">
                                    <i data-lucide="brain" class="w-4 h-4 text-indigo-600"></i>
                                </div>
                                <h5 class="font-medium text-sm">AI & Deep Learning</h5>
                            </div>
                            <ul class="space-y-2 ml-7 list-disc text-sm">
                                <li>Learn PyTorch or TensorFlow CUDA integration</li>
                                <li>Study cuDNN and TensorRT</li>
                                <li>Implement custom CUDA kernels for deep learning</li>
                                <li>Explore large language model optimization</li>
                            </ul>
                        </div>
                        <div class="p-4 bg-gray-50 rounded-lg">
                            <div class="flex items-center mb-3">
                                <div class="p-1 bg-green-100 rounded-full mr-2">
                                    <i data-lucide="bar-chart" class="w-4 h-4 text-green-600"></i>
                                </div>
                                <h5 class="font-medium text-sm">Data Science</h5>
                            </div>
                            <ul class="space-y-2 ml-7 list-disc text-sm">
                                <li>Learn RAPIDS ecosystem (cuDF, cuML)</li>
                                <li>Study GPU-accelerated data processing</li>
                                <li>Implement custom CUDA algorithms for analytics</li>
                                <li>Explore large-scale data visualization</li>
                            </ul>
                        </div>
                        <div class="p-4 bg-gray-50 rounded-lg">
                            <div class="flex items-center mb-3">
                                <div class="p-1 bg-amber-100 rounded-full mr-2">
                                    <i data-lucide="flask-conical" class="w-4 h-4 text-amber-600"></i>
                                </div>
                                <h5 class="font-medium text-sm">Scientific Computing</h5>
                            </div>
                            <ul class="space-y-2 ml-7 list-disc text-sm">
                                <li>Study numerical methods on GPUs</li>
                                <li>Learn CUDA-accelerated simulation techniques</li>
                                <li>Implement molecular dynamics algorithms</li>
                                <li>Explore climate modeling optimization</li>
                            </ul>
                        </div>
                        <div class="p-4 bg-gray-50 rounded-lg">
                            <div class="flex items-center mb-3">
                                <div class="p-1 bg-blue-100 rounded-full mr-2">
                                    <i data-lucide="image" class="w-4 h-4 text-blue-600"></i>
                                </div>
                                <h5 class="font-medium text-sm">Computer Vision & Graphics</h5>
                            </div>
                            <ul class="space-y-2 ml-7 list-disc text-sm">
                                <li>Study OpenGL/CUDA interoperability</li>
                                <li>Learn image processing algorithms</li>
                                <li>Implement real-time video analytics</li>
                                <li>Explore GPU ray tracing</li>
                            </ul>
                        </div>
                    </div>
                </div>
                
                <div class="p-4 bg-yellow-50 rounded-lg border border-yellow-200">
                    <div class="flex">
                        <div class="p-2 bg-yellow-100 rounded-full mr-3 mt-1">
                            <i data-lucide="lightbulb" class="w-5 h-5 text-yellow-700"></i>
                        </div>
                        <div>
                            <h4 class="font-semibold mb-2 text-yellow-800">Learning Recommendation</h4>
                            <p class="text-sm text-yellow-700">The most effective way to learn CUDA is through a combination of structured courses, reading documentation, and hands-on projects. Start with simple algorithms, gradually increase complexity, and use profiling tools to understand performance characteristics. Joining forums and contributing to open-source projects can accelerate your learning curve significantly.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="conclusion" class="mb-20">
            <div class="border-l-4 border-primary pl-4 mb-6">
                <h2 class="text-3xl font-bold">Summary & Conclusion</h2>
            </div>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                    <h3 class="font-semibold mb-4">Key Takeaways</h3>
                    <ul class="space-y-3">
                        <li class="flex items-start">
                            <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                <i data-lucide="check" class="w-4 h-4 text-primary"></i>
                            </div>
                            <div>
                                <span class="font-medium">CUDA is a Powerful Platform</span>
                                <p class="text-sm text-gray-600">CUDA enables massive parallelism on NVIDIA GPUs, offering significant speedups for computationally intensive tasks.</p>
                            </div>
                        </li>
                        <li class="flex items-start">
                            <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                <i data-lucide="check" class="w-4 h-4 text-primary"></i>
                            </div>
                            <div>
                                <span class="font-medium">Performance Requires Careful Design</span>
                                <p class="text-sm text-gray-600">Optimizing CUDA code involves understanding the architecture, memory hierarchy, and execution model to achieve peak performance.</p>
                            </div>
                        </li>
                        <li class="flex items-start">
                            <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                <i data-lucide="check" class="w-4 h-4 text-primary"></i>
                            </div>
                            <div>
                                <span class="font-medium">AI is Driving Innovation</span>
                                <p class="text-sm text-gray-600">CUDA plays a critical role in modern AI development, with specialized libraries and optimizations for deep learning and LLMs.</p>
                            </div>
                        </li>
                        <li class="flex items-start">
                            <div class="p-1 bg-primary/10 rounded-full mr-3 mt-1">
                                <i data-lucide="check" class="w-4 h-4 text-primary"></i>
                            </div>
                            <div>
                                <span class="font-medium">Ecosystem is Rapidly Evolving</span>
                                <p class="text-sm text-gray-600">CUDA continues to evolve with new features, hardware support, and expanding application domains.</p>
                            </div>
                        </li>
                    </ul>
                </div>
                <div class="bg-white rounded-xl border border-gray-200 p-6 shadow-sm">
                    <h3 class="font-semibold mb-4">The Future Outlook</h3>
                    <p class="text-sm mb-4">CUDA's role in computing is expanding beyond traditional domains as parallel processing becomes increasingly essential for handling growing data volumes and computational demands.</p>
                    <div class="space-y-4">
                        <div class="flex items-start">
                            <div class="p-1 bg-blue-100 rounded-full mr-3 mt-1">
                                <i data-lucide="trending-up" class="w-4 h-4 text-blue-600"></i>
                            </div>
                            <div>
                                <span class="font-medium">CUDA DTX & Scaling</span>
                                <p class="text-sm text-gray-600">The evolution to data center-scale computing with CUDA Distributed Execution will enable even larger models and datasets.</p>
                            </div>
                        </div>
                        <div class="flex items-start">
                            <div class="p-1 bg-blue-100 rounded-full mr-3 mt-1">
                                <i data-lucide="trending-up" class="w-4 h-4 text-blue-600"></i>
                            </div>
                            <div>
                                <span class="font-medium">Hardware/Software Co-evolution</span>
                                <p class="text-sm text-gray-600">Future CUDA versions will continue to align with new hardware capabilities, with specialized features for AI and scientific computing.</p>
                            </div>
                        </div>
                        <div class="flex items-start">
                            <div class="p-1 bg-blue-100 rounded-full mr-3 mt-1">
                                <i data-lucide="trending-up" class="w-4 h-4 text-blue-600"></i>
                            </div>
                            <div>
                                <span class="font-medium">New Application Domains</span>
                                <p class="text-sm text-gray-600">CUDA is expanding into fields like quantum computing simulation, digital twins, and next-generation communications.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="bg-dark text-white rounded-xl p-8 mt-6">
                <div class="flex items-center mb-6">
                    <div class="p-3 bg-primary rounded-full mr-4">
                        <i data-lucide="lightbulb" class="w-6 h-6 text-dark"></i>
                    </div>
                    <h3 class="text-2xl font-bold">Final Thoughts</h3>
                </div>
                <p class="text-lg mb-4">CUDA represents one of the most significant advancements in computing architecture of the past two decades. By democratizing parallel programming and providing tools to harness massive GPU computational power, it has enabled breakthroughs in AI, scientific discovery, and data processing that would otherwise be impossible or prohibitively expensive.</p>
                <p class="text-lg">As we move toward an increasingly data-driven, AI-powered future, mastering CUDA and GPU programming principles will remain a valuable skill for researchers, engineers, and developers who need to solve the most challenging computational problems of our time.</p>
            </div>
        </section>
    </main>

    <footer class="border-t border-gray-200 py-8 mt-12 text-center text-sm text-gray-500">
        <p>Built By <a href="jianwei.jarvis@gmail.com" target="_blank" class="text-primary hover:underline">Jianwei</a>.</p>
    </footer>

    <script src="main.js"></script>
    <script>
        // Prevent zooming
        window.addEventListener("wheel", (e)=> {
            const isPinching = e.ctrlKey
            if(isPinching) e.preventDefault()
        }, { passive: false })

        // Initialize Lucide icons
        lucide.createIcons();
    </script>
</body>
</html>
